{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_revgrad import RevGrad\n",
    "\n",
    "train_MNIST = datasets.MNIST('', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test_MNIST = datasets.MNIST('', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "train_USPS = datasets.USPS('USPS', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test_USPS = datasets.USPS('USPS', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "trainset_MNIST = torch.utils.data.DataLoader(train_MNIST, batch_size=32, shuffle=True)\n",
    "testset_MNIST = torch.utils.data.DataLoader(test_MNIST, batch_size=32, shuffle=False)\n",
    "\n",
    "trainset_USPS = torch.utils.data.DataLoader(train_USPS, batch_size=32, shuffle=True)\n",
    "testset_USPS = torch.utils.data.DataLoader(test_USPS, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")\n",
    "    \n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the transformation\n",
    "\n",
    "p = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.RandomCrop((28, 28)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that transforms the data according to how it is done in the paper. First interpolating so that images are 32x32 and than performing 'random' 28x28 crop\n",
    "\n",
    "def transformdata(data):\n",
    "    data_transformed = [] # initializing the entire (batched) dataset as an empty list\n",
    "    \n",
    "    for batch in data:\n",
    "        \n",
    "        images = batch[0]\n",
    "        labels = batch[1]\n",
    "        \n",
    "        images_transformed = torch.zeros(size=torch.Size([32, 1, 28, 28])) # initializing the transformed images with the same shape as images (32, 1, 28, 28)\n",
    "\n",
    "        for i in range(0, len(images)):\n",
    "            \n",
    "            image = images[i]\n",
    "            \n",
    "            image_transformed = p(image) # transforming the image with predefined transformation \"p\"\n",
    "            images_transformed[i] = image_transformed # replacing zero tensor (1, 28, 28) in images_transformed with the transformed image\n",
    "            \n",
    "        batch_transformed = [images_transformed, labels] # transformed batch is simply a list of batch of images in [0] and batch of labels in [1]\n",
    "    \n",
    "        data_transformed.append(batch_transformed) # appending to the empty dataset list\n",
    "        \n",
    "    return data_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming data\n",
    "\n",
    "train_MNIST_transformed = transformdata(trainset_MNIST)\n",
    "test_MNIST_transformed = transformdata(testset_MNIST)\n",
    "train_USPS_transformed = transformdata(trainset_USPS)\n",
    "test_USPS_transformed = transformdata(testset_USPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting 2 images from MNIST datset (2 to make sure I didn't make a mistake in transforming the dataset)\n",
    "\n",
    "batch_MNIST_0 = train_MNIST_transformed[0]\n",
    "images0 = batch_MNIST_0[0]\n",
    "\n",
    "plt.figure(figsize=(5,5)) # specifying the overall grid size\n",
    "\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1)    # the number of images in the grid is 5*5 (25)\n",
    "    plt.imshow(images0[i].view(28,28), cmap=\"gray\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plotting 2 images from USPS datset (2 to make sure I didn't make a mistake in transforming the dataset)\n",
    "\n",
    "batch_USPS_0 = train_USPS_transformed[0]\n",
    "\n",
    "images0 = batch_USPS_0[0]\n",
    "\n",
    "plt.figure(figsize=(5,5)) # specifying the overall grid size\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1)    # the number of images in the grid is 5*5 (25)\n",
    "    plt.imshow(images0[i].view(28,28), cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from model import fNet, gNet, Discriminator, hSim, SimNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights_disc(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.uniform_(m.weight)\n",
    "        nn.init.uniform_(m.bias)\n",
    "#         m.bias.data.uniform_()\n",
    "#         m.bias.data.fill_(0.01) # do we need something like this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlIAAABRCAYAAAAZ1Ej0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABMoUlEQVR4nO29aYyc53Uu+Hy17/tevVXv3WyuTWqlI9mWYsdBFGdxYmQZDzCBgwA3mIssmGDmR+6fAfInFwmCiwE8uEHmBgnuOL4JxnHiWIkUmZIsUaTEpcne99r3fa+umh/kOaqmmmQv1dXV1PcADZLNrurv1Pd+73uW5zxHaLVaECFChAgRIkSIEHFwSE76AkSIECFChAgRIk4rREdKhAgRIkSIECHikBAdKREiRIgQIUKEiENCdKREiBAhQoQIESIOCdGREiFChAgRIkSIOCRER0qECBEiRIgQIeKQOJIjJQjCVwVBWBIEYVUQhD/q1EX1EkQbTz+edfsA0cZnBc+6jc+6fYBo4+cSrVbrUF8ApADWAAwDUAC4A2D6sO/Xi1+ijaf/61m3T7Tx5K9NtFG0T7Tx2bLxoF9HyUg9B2C11Wqtt1qtGoD/DuDnj/B+vQjRxtOPZ90+QLTxWcGzbuOzbh8g2vi5hOwIr/UC8Lf9OwDg+Ud/SBCEbwP49sN/zh7h950YBEEg+ff/CT1uoyAIEAQBEokEgiCwx7yzs/O01z3Wxl6y77Bosy8P4L/t8f/Pko2nZp0KgsD/3iPy3et1x2IjPTME+v10fc1m87HX1Gn0yrMokUggl8uh0WhgNBqh0WiQyWRQrVaRz+exs7Pz1H1lL4jPYudtpP2evmittlqtY1u7p2m/OSparZbwpP8/iiO11xt/5m61Wq3vAPgOsOuDP83oaRsNBgNsNhuGh4dhMBhQr9cRjUZx+/Zt1Ot1NJvN/bzNLht6yb4OIIEev4cdQk/aKJFIoNVqodFooNfrYbFYoFKpoFAoUC6XEY/HEYvFkMlk9vN2HbFRr9dDo9FgaGgIUqkUAFAoFFCpVGAwGNBoNOD3+1Eul1EqlfZta4dwIs+iVCqFw+HA5OQkvvGNb+DFF1/E+Pg4vvvd7+L+/fv4/ve/j2QyiWQyeZRfIz6LOJqNcrkcCoUCLpcLer0e/f39HBAUCgUUi0VsbGygVCqhUCgcZzDwebiPj8VRHKkAgP62f/cBCB3tcg4GmUzGEZNcLodUKmWPXKPRQKlUolgsolqtIpvNol6vo1ar7deZ2Atdt3G/kEgkUKvVcLvdGB8fx/PPPw+Hw4FisYj5+XnMz8+j1WqhVqs97a2OzUa6N1qtFnK5nO+fXC6HTqeDSqWCRqPZlRl4FJRdo4MuHo+jVquhXC5jZ2dnPxuFAj16DzuInlynarUaGo0G/f39cDgc8Hg8GBkZgclkgkKhQDQaxccff4xarbYfR6pjNqrVaphMJkxNTUGr1UKr1SKfz6NSqcBisaBWq2FpaQmZTAbJZJKj/FqthlqthmKxiHq9jkajset9KctFa/IQ+86J3EelUgmNRoPh4WFMTk5iZmYGNpsNgiAgm80inU6jUql8xt5DQHwWDwlBECCTyWCxWGAymXDlyhX09fXhpZde4ixqLBZDMpnEm2++iVgshq2tLdRqNTQaDd4rO+RY9eR+000cxZG6AWBMEAQfgCCAbwL4tY5c1T4hk8mg0WhgNpuh0WigUCggkUggkUhgNpuh1+sRj8eRz+fRarVQKpXQbDbRaDQO60x13cb9QiKRQKPRwGazYWRkBBcvXkR/fz9SqRSq1SoUCgXq9fqutO9jcGw2SiQSSKVSGAwGqFQqqNVqdp4cDgdnKCgrAOAz19psNtFsNhGLxZDNZtFsNpHP59FoNPZVwgRgAfD9jhvXW+i5dUrBjclkwtDQEAYGBjA6OoqzZ8/CZrNBLpdjbW0N4XAYa2tr+3nLjtmoVCqh0+kwMDAAi8UCq9WKUqmESqUCm82GWq0GmUyGeDyOYDDIjhRF/LS3tK89QRAglUohlUq5tHKIg+tE7qNSqYRWq4XX68Xg4CB8Ph+MRiMAIJ/PI5fLoVqtdsKREp/FQ0IikUChUMBkMsHtduPcuXMYHx/H1772Nd4/t7e3EQ6HsbW1BaVSiUwmg2KxiHK5DODBXnqY0uwe6Ln9pts4tCPVarUagiD8BwA/wgMW/1+2Wq37Hbuyp0AqlcJsNsPr9eL8+fN8EEulUkgkEng8HpjNZvj9fiSTSczNzSEcDmNzcxOJRIIzGAfEd7tp40GgVCoxODiI6elpXLx4EePj47Db7QAelC4UCgUqlcp+3qrjNtKhYrPZYDKZcP78eZjNZnZ29Xo9hoeH+X7uxVWh96GHf3NzE7FYDO+99x7C4TCWlpYQiUSQSqWe5iSnevUedhA9tU6lUikUCgWuXr2K0dFRfOUrX4HD4YDL5YJGo0Gr1cLS0hL8fj9u3bqFeDy+n7ftmI2NRgONRgP1eh0ajQZnzpyB0WiEVquFTCZDs9nEK6+8wo4UBWOhUAiRSAS3b99GKBTibBUFNQqFgp+7Wq2GcDi8Z+aqGzbuF4IgwGg0wul0YnZ2FtPT07Db7SgUCojFYlhbW8PW1hYKhcJ+sttPg/gsHhJarRZDQ0N47rnnMDMzgy9+8Yuw2+3MW2s2m7DZbDAYDPjmN78Jv9+Pjz76CGtrawgGg4hEIiiVSsjlckep0BB6ar85CRwlI4VWq/XPAP65Q9fyVLRHeUqlEkajES6XC0NDQ/B6vTAYDJz1cDgcMJlMUKlUsNlsaDQaUKlUqFQqqFaraDabKJfLB4oQW63W/3mM5h0JEokEer0eBoMBZrMZWq0WKpUKMplsV8nzaeikjXS/ZDIZlEolHA4Hlx6tViusViuXUjweD0wmExwOBztSlH0iSKXSXVE9ZRx1Oh1nEPL5PGq12pPua6RT9vUqemWd0v03GAwwGAwYHR3FxMQEhoeHYTKZYDabIQgCl9vr9Toqlcq+ApxO20hl752dHcjlchiNRlgsFl5vRLYmx6/RaMBgMMBoNKJcLjMhe2dnBwqFAmazGQqFAkqlEoVCAYVCAblcDsVicd+OVLfvI5HLKTPscrlgsVggkUiQz+cRDoeRTqeRy+VQr9c7kc0Qn8VDQBAEXmMejwdDQ0OwWCy7mgEqlQqsVivkcjn6+vogl8tRKpWgVqu5gpPJZLC+vs7lvsOiV/abk8SRHKlughwks9nMi2FsbAxnz57Fq6++isHBQWi1Wu5eIIfL5/OhXq/j/PnzuHfvHlwuF9599134/X6OELvVjXOcoAPLaDTCZDJBJpNxCaK9tNAtUImVnDu3240rV65genoaL7/8Mmw2G2w2G18jbcxUhm21WrvKB4IgQKlUQi6XQ6lUwuPxwO12w+v1IhQKYXBwED/60Y9QKpWQSCSemft6WiEIAvMXZ2dncebMGfzSL/0SvF4vO8vNZpNLzQqFAlqtFlarFYlEoqvXSoFGIpGAXq9HOBzmgITWoiAIsFgssFgs/LrR0VEUi0VcvnwZoVAIiUQCzWYTGo0GExMTzAMMhUIIBoP40z/9U4TDYQ7keg0qlQoGgwEjIyMYGRnB5OQkbDYbisUi7t27h9u3b2NjYwOJROIo9AgRR4RMJoNOp8Pg4CCmpqZw7tw5qFQqZLNZ3Lp1C36/H9vb23j99dcxPDwMp9MJh8OB6elpVCoVlMtlfPzxx1heXsZf/uVfdqJp4HOPU+NIqVQqaLVanD9/HjabDYODg3C5XOjr64NOp0O9XkcikeBNjzqBdDodJBIJTCYTBgYGUKlUkMlkoNFomOOwz5JXT0Mul8PhcPBDI5PJUK/XUSgUUCqVur7xKRQKqFQqjIyMYGhoCC+88AJ8Ph88Hg8cDgc0Gg0EQeDoKZVKoVwuI5fLMREyn8+jVCqh1Wqxo2gymTibpVKpoNPpYLfbMTY2ho2NDaTTaZRKJW7P7jbayfPk9LWj2WyiUql8Jtu2F+gQp9ITHcC97CDKZDLIZDK+RxTsjIyMQKvVolKpYGFhgXk4FouFsyBOpxPj4+OIx+MIhUJdW68U1V+6dAkejwderxdqtRqNRmNXswrx+eRyOSQSCZe2KBNus9mYf1Iul1Gv1yGXy7GzswOJRAKDwYB8Pg+5XM6E316CVquFy+XC+Pg4JiYmYLVaIZVKEYvFsLKygjt37iCVSqFSqfT0GnyWQc06lL03m818/iWTSVy/fh2RSAThcBgajQZ+vx9TU1MwGo1wOBzc5We325HL5eDxeFCr1URH6og4FY4ULR6r1YovfOEL8Pl8OHv2LFQqFZRKJWq1GkqlEm++giDAYDDsOsyMRiOGh4dhsVhQLpdhMBiwvr6OZrOJarV66jcGhUIBr9eLvr4+eDweAGCnMZfLcdmiG3ZKJBKoVCoYjUacPXsWV65cwbe+9S0oFAomQlIWqlwuI5VKsRMUCoXY6aM2+GazCYVCAafTib6+PoyOjnKXpl6v58g/HA6jUqlgbW3tM+TfboEcfq/XC61Wy+Ur4NOOQ4roiSD/OBDXgcqW6XSaP5teXa+UhfL5fBgbG8NXv/pV+Hw+uFwuXo8ff/wx83CoRGE2m9HX14eLFy9idXUVi4uLXXP+fT4fLly4gFdffRUWiwUOh4O78pLJJLLZLLa2tmAymWC323lfqdfrnB2gMkoqlUI+n8fKygpkMhkUCgVKpRLq9TqMRiPy+TyUSmUnib4dATl6AwMDOH/+PHOjcrkc/H4/5ubmcP36dSQSiaeVzkUcI+g+2Ww2eDwe5kGFw2FEIhG8/fbbvGbT6TScTidSqRQGBgYwOzsLq9UKnU4Hh8OBUqmEoaEh5PN5bG5unrRppxo970jJZDKoVCq89NJLuHz5Ml599VXYbDZYrVak02n4/X7cuHEDfr8f9+/f5840SsO/8cYb6O/vx+DgIARBgMlkwqVLl+D1elGr1bC4uIh33nmHHY3TBolEgitXrmBsbAyzs7Po6+sDAGxsbCAcDuO73/0uVldX9809OSrIkTh37hyGhobwjW98A/39/ZDL5UwWLxaLyOVyuHv3Lra3t7G8vAy/349MJoNUKsXXSXw24EH5RaVSYXJyEplMhonAOp3u2G3aLwRBgMfjweDgIF577TW43W6MjY3t4nzRmiuVSigWi090inZ2dlCr1Vhb6d69e8hkMru6FHsFOp0ORqMRU1NT8Hg8eP755+HxeDA5OYlGo4FYLIZr164hGo1ie3sbo6OjUKlU2NnZgUwm4+zU0NAQZxuLxWJXrl0ikbDTI5VKUavVEAgEEIlE8M///M+IRqOIx+OckTIYDFAoFNwNazAYYLVaYTAYOOO4tbWFYrGIfD7PWdeFhQWWVeilvaY98HG5XHA6nTCbzchms1hdXcUPfvADzM/PI51OH0SLTsQxgErmlCCggJL2imQyyXvE5uYmkskkO/hOp5MzwZVKBYVCAclksmvP2bOMnnakSIeFCHMzMzMYGBiAXq+HTCbjQ2ZxcRHLy8u4c+fOZxypqakptFotJthR+lqtVmNychKVSgU6ne7ESkFHAT1Ug4ODGB4ehsfjgcFgQKvVQiaTQSgUwv3797vKBaMyzdDQECYnJzE5OQmz2QypVIp6vc4l2Hg8joWFBayurmJhYQHBYJBbq9t1d9oVpmUyGb83ZZx6yZmgjiev14uZmRnmMLRnpKrVKjsJhULhiY4UdZKFw2Ho9XrOZJXL5U60nh8ZxIOTyWR8CI+NjWFwcBBnzpyByWSCTqdDNBpFLBbDwsICE5ZNJtOuTDCVb9Vq9S5NuG6g0WigVqtxRx1JG8RiMSwuLnLnL9lKXbDVapWz3VRmkcvlqNVqCIVCSKfTzNdrNBq7/t5r65bK5FQqIs5NNBrFwsICotFoz3K7Ps/Yi/tK2f5sNotqtYpoNAqr1cpl6nq9zvsPOfa9jIPuAyfxbPW0IwU82KyVSiUsFgv6+vpgNBohlUoRDoexvLyMDz74ADdu3MDm5uauQ7hWqyGVSuE73/kOBgYG8M1vfhOjo6OYnJxk/aJLly5Bo9EglUrh448/xurq6glbezBQZ9GFCxcwNTWFgYEBCILAQpWBQAAbGxtcHusGTCYTRkZG8LM/+7O4dOkSXC4XZ6M2NjawsbGBN998kzOIFLVTlP64Q4Y6qcxmM+x2OwwGA/OsegHk8Pf39+PcuXM4c+YMnE7nZ35OqVTi/PnzTLJ/EuhnqtUq/H4/fD4f/vVf/xU3b97kQ/mkIAgC7HY7jEYjxsbGMDAwgLGxMS4J6fV6ZDIZXLt2DQsLC9jY2MD169dRKBRYRbzRaKBQKCCVSiEYDCKZTGJtbQ2JRKKrTvLc3BxyuRz6+vpYQoRKjiMjI2i1WlhZWeFsjEKh4Owq7U8ajQYqlYqzA0TqJe064rp1u+ljP1AqlbvEN00mE5rNJubn5/HJJ5/g/fff5wNYxMmCnPxUKoVAIIBwOAy73c7inLOzs1haWmKRWApAibNaKBQQDAZx69YtLC0tYXV1Fdls9qTNYjw64ozkjOjvTwKVyykY6iYFoqcdKRonMTAwAJvNxorYJMJISsP5fB7lcnnXwUSbVjweZ9Vkq9WKcrkMtVrNkaXJZILL5WJS+mmIuGihWSwWeDweOJ1OLocQ76hUKqFUKnGk3S2QZpDJZILFYmHSezabxfb2Nj+84XAYiUQC1WqV22+ftPBpLVAXIGUuesWRale7LpfLKJfLqFQqkMlkn7lGuVx+oPdWKpWwWq0YHByEyWQ6UbtJWFOlUqG/vx92ux1nzpzhkqZerwcAhMNhRKNR3Lt3D6urq/D7/czxIo4QANTrdZRKJUQiEUQiEayvryOdTnc1O0yZFyLoFotF5qL09fXxngFgl0NBfEzavEulEiuZU/aV+ES96EABnwaqdrsdTqcTLpeLn9lUKoVMJtNzpcjPMyirXSgUEIlEEAqFYLVaYTKZ2CEuFosIBoMoFAqQyWQwm80wGo1QKBQcuPr9fv6ZDuiBdQxUttTr9Vxu1uv10Gq10Ol0T3SmisUiotEo84KJAtGN86+nHSmZTAan04lXXnkFY2NjfIhQizstJFLabQd5pJSS39jYgMlkYpVelUoFk8kEp9MJn8+Hu3fvMoG0150p2vx8Ph/OnTuH0dFReL1edqRIT4k0lbppD10bSTE0Gg3k83nOHl6/fh1zc3PIZrPI5/P7fl/qBCMhR9L16SVHqtFoIB6PY3NzE1tbW2g2mxgeHt51je2RFXWYPs0GqVQKk8mEM2fO4L333oNKpToRu6mU7HK5WM6ir68Ps7OznC1MJBJIp9P44IMPsLW1hZs3b7JQaqPR+IwTSQHQ4uIiNjY28NFHH8Hv93d13cbjcZTLZSwsLAAABgcHYTQaYTQacfnyZRgMBrz//vtIp9PIZDLs+JNj1Gg0er488jhQQDk5OYnx8XGMjY2xDEkgEEAsFuuJMrKIB2i1WigWi4jFYrh//z40Gg0qlQqef/55aDQafPGLX4RcLkckEkEgEADwQKZjYGAAOp2OZX8++eQTbG1tIZvN9pSDr9PpoNfrMTo6ypINlPEeGhqCSqXin3008eH3+3Ht2jXcuXMHq6urWF1dRT6f70rGrWcdKTqQyfkhgTuaPE5pTardPwnVahVra2tQq9UwGAxclpDL5TCbzfD5fJicnEQ2m8XKysqJdXztB3SY6fV6DAwM4MyZM3A4HNDpdCiXy0gmk9jc3MTm5ib8fv+J2kGReSqVwr1791i9OpfLHfjgUSgUcLvdcDqdsNlsXEbpJbRaLe4crdfrnJUjsjlxbPr6+lj6gfTR3G43Dx0lLl/7+1K2q9uHGmU/6ZqcTiemp6cxPDyMS5cuMRexUqlgY2MDi4uLCIfD+PDDDxGLxRAIBHbJbzy6aVMnYz6fRyKRwObmJgqFQldLezs7O6hWq9y5RHwvs9nMXXZXrlxBLBZDOBxGPB5njgkpSZ9WtGeQTSYTDAYDEokEd+vtU2X+cwMKhEi1ngKDnZ0dFls97vVAs0YDgQDUajXy+Tz0ej03CkxMTCCVSmF1dRXVapVlD0KhEFZWVrCxsYFAIMBK/CeJdtFmhUKB559/nsvrJDhKEzF0Oh1kMhm/jjToyAaHw8GdiZOTk/jwww8RCARw+/btTgnIPhY96UjR5q1UKqHX6+F2u2EwGFh/hTzyeDyOVCr11NRdrVZDMBhkMiUtLI/HA71ezzoyiUQCgUCgp1PZ7Y6Uy+ViJ5NU20lCgMZXnER2jbIz9Xod1WoVmUwGq6urCAaDiEajrLGzX9BcKbvdviuNTQ4KORr74R0dN+LxOBOVabMlkML72bNnIQgCCoUCp7JnZmbgcrlgMBgglUo/40hR1oMkEbqFdoK1zWZjXaiJiQnMzMxArVbzkOHt7W3cu3cPW1tbuHPnDuu0PQm0EVIWNRqNdsmy3ddApH7ggS5UoVCAw+HgdXb27FmEQiGOiKVSKQdwvbpX7Ad0iNGoJq1Wi3A4zKWjVCp10pfYM2jnG+l0Omi1WqjValbnJ27cca8H6gyNxWKQSqUoFArw+XwAgLGxMfT39/PeUiwWYTKZIJFIEI1GsbW1hdXVVcRiMeRyuWO9zqeBmlWUSiXUajV0Oh3Onj2LmZkZzMzMQKfTwWAwQKlU8l5Kmfi9HCmTyYSxsTHu/i0Wi1CpVFheXj725EhPOlJSqZSzRXa7fdf4l2g0Cr/fj+XlZWxtbbGuyZNQq9V48nUul4NGo0G5XOb3HRwcxHPPPQez2czaUplMpqe6wsi51Ol0cLvdeOGFF1hiQK/Xo9FoYH19HXfv3sUHH3yAmzdvIhQKdZ0gWiwWEYlE8OGHHyKdTkOv12NhYQHXr1+H3+/nKP4gIA2xyclJ+Hw+PuAA8OaVyWQQDAaxsbHxGb5cN0Gcr0KhwPeMQBsxlZtrtRqsVit3lyoUCuj1eraNyJPpdBpbW1t49913sbKycqjP8KAgB8pqtcJoNPL8xq985SvQ6/XQaDSo1+uIRCL45JNPsLS0xMrX6XSapR2eBhIIJM7bSaHRaGBra4ubNOx2O8xmM4aGhjA4OIg33ngDiUQCW1tbuH79Ora2tnDr1i0UCoVdZb5e2S/2A0EQmCdKTTzFYhGBQACrq6vY2NhALBY76cvsCWi1Wmg0GoyPj8PhcGBsbAxOpxMmk4lFS7/3ve8hFApxSe04QcEVae394z/+I3w+H1QqFbxeL772ta/hpZdeQqFQwMLCApfZNzY2EIlEkM1mT7xkq9FoYLFY8Pzzz7M+4Llz5+ByuWCz2SCTyVj8dj8UCJlMxo6XxWJBvV7H8PAwJBIJlpeXMT8/z9nxTqMnHSlK92k0Gq6ZKpVKSKVSVq0mgvl+uBTkwWezWcRiMRYsa2+5ttlsKJVKTGSmYY69sjG2Zwbcbjfr9dCg5nK5jHg8jnA4jEAggHQ6jUKh0PXrr9VqXCJtNBpwOp0IBAKcqTlI6zetA+pOtNvtMJlMUKvV7KBQpoYaD+Lx+ImOh6G1uJejQ45UuVxmEVGKxCjCVSgUkEgk2NnZYcJ6MBjE9vY2OyndEESUy+VQq9WsRD8zM4PR0VEMDQ2hWq1yJyFxNdbX17G1tYVYLIZSqbTv30NOFDlnJ4lqtcrE8Vqthnw+D41GA5PJxM+ZVCrlrLXBYACAXV1CxLHslX3jaSBdIcq0FYtFpFIpxOPxU9Ea3w6aQfdoALNfUIaEaAPt1AF6RsfGxuByuTA5Ocl6WxKJBEajEQaDoesK4VTuD4fDEAQBCwsLrOOn1WpRKBQwNzfHsxJTqRRyudyJSXC062C5XC64XC5MTExgcHAQ4+Pj3Jmv0WjYgSLQM7azs8P3uL0qQX/Svkpd02NjY6hWq3w+fm4cKapBW61W2O12uFwuqFQqSCQSpNNpxONx7tY7wABQFAoFLnvZbDbU63VWR3e73VCpVHC5XEin00gmk/sa49EtkGL05OQkXnrpJfzWb/0WT5gvlUpIp9O4ffs27t69i/v37yObzZ7ItedyOZ4qbjAYMDU1xbytg/IHKOU7MzOD8fFxTE5OMpcI+LQVOBaLYX5+HnNzc5ibm+tZvRtyhs1mM2/GNHvu3LlzsFqtnF0sFovY2NhANBrFj3/8Y/j9fnzyySfskB63fQaDAR6PB2+88QZmZmbw2muvQaFQoNFoYGVlBQsLC/jBD36AQCCAtbU11Gq1Qzl4FosFVqsVExMTiEROfoYtNUdQSZrKC/l8nksG+XweOp0OiUSCFaQrlQqPOiJHs9chCAJsNhtrYO3s7CAQCODu3bsswEkjb3odFKTQPk6O4UEcKhpKPTIyws0ydJCTZA51zlI1gw58arbo9homjmE0GkU6nUY0GkWhUMDFixc5OKEgkzowT8rRp/3P5XLB4XDgS1/6EgYHBzE7O8sD7SkD1e4Y0TlMXej5fJ4dKRLHpUkR9XqdhUo9Hg8sFgsUCgVcLhf0ej3efPNNbG9vd9y2nnSk6AM3GAy7BhEDewuQ7Re06EhpuFKp7CorUC2WxAB7pSMMAHfCnTlzBsPDwxw1kcRDIBCA3+9HNBo9kIPZaTSbTTQaDR5Ls7y8zCTMgxz+NPDYarXi7NmzGB8fZwkM+j1EZA+Hw1hdXUUymeyZYcUULVFtX6lUctbp/PnzcLvdmJ6e5kPM4XBArVajWCwik8kgHo9jfn4eoVAI9+7dQywWQyKROHYhUhoObTQa4fF4MDw8jJGREchkMsRiMdy4cYMlDTY2NnhG4lE2Z3rWeul5a1eK9vv9uHnzJsbHx7nMXK/XcfXqVS7lplIpDmboQOslasBeEAQBZrOZx4Y0m01ks1kWzN1v1oLuHR1gJBUBgAVIn6bifxQbaK/Q6XSYmZnhMtxBRV2J8zQ+Ps7vR+cNnQ12u52blmgPbh8Kf5KZcMpit++BSqUS586d49Lt6uoqnxXddvalUilTUwYHB3H27Fn09/ezk9MuFUOyIpVKhaV8YrEYisUiDzWXSCRwOp3QarUsS1KpVKBWq3kCAfBg2obT6cTU1BRWV1eZE0mNa514TnvWkZLL5dxF8miK77BoFzikER3tg0hpI9hL++ckIQgC1Go1TCYTLl++jLGxMd4kms0m/H4/VldXsba2hnA4fCBZgU6DnNVCoYBCocCL/iCgzdFsNqO/vx8vvPACRkdH4XQ6mUdDJT0iUN67d483/14A1fcpGCC9MovFgqtXr8Lr9WJ6epqjWtLuicViPDbn5s2b2N7eZi5OsVg89o1aIpFArVazbhW1xe/s7GBjYwN/8zd/g7W1NYRCIXbYj8rX6kVng7rxotEoGo0G3nrrLdTrdQwODnIX0cjICI8u2tra4pLf5uYmk7R7ZT3uBUEQWFLEaDQim80ik8mwptd+7ytlgyhQoJIKVQEok0BZg06CzgrKrD333HN8bhy0q1en00Gj0WBsbIzLnbQOSG2/nVZA2NnZ4a6wk1zLFMRSQwoRuV9++WVMTk5iYGAA77//Pm7fvo14PN51R4r2w4GBAUxPT+PKlStwu91M2G8PpogDViqVEI1GkUwmsbKygnQ6je3tbT4jKHtIa6xQKLD2VF9fH2sPUiVjdXWVCfqk/N6JbuiedKRoI//CF76AsbExdmyOukgpwgoGg1AqlVhcXMTQ0BBMJhOATw9wegB7wZki4r3D4cDQ0BAuXLjAonmCIKBer2N+fh737t3D2toaMpnMSV/ykSGVSqFUKjE0NITz58+jv78fNpuN+UMAeP7cj3/8YywtLeHWrVsn1oUik8l4JqRarYZarYbFYoFOp4PT6YTFYuGBy1ardVdHCm1+6XQa2WwWd+7cwcLCAm7duoXl5WWkUikmhnZzkyZ+Gn3RgVKpVLiMd9gOwvYOy17nE1UqFSSTSXzwwQcsMEolg9nZWZa4UKlU6Ovrg1Qqxfr6OmQyGYLBIPx+/0mb8FgIggCn08n2HKQ0S2ueeJtarRZjY2Po6+vDhQsXADxwMLa2thAKhfD2228zR7IT100OrNFohNVqxezsLIaGhvD666/vWcl4FLSeiS9Ur9d57y+Xy5wZrtVqqFarPE3B5/PxHkQO1MbGBlZXV7l01m0QN0yj0WBwcJCbcT788ENks1lMTk5CJpNhcHAQW1tbiEajJ9LYoVQqWbeRRoeRY0r3ie4FlSq3trZ4DS0uLiKdTjOZXyqVcrMV8aWLxSIsFgtMJhOmpqZgt9sxOTkJo9GIwcFBfPnLX8b09DQ3JpEExDPpSNGh5PF4YLfb+YM+6oZLH1g+n2dCpdls3vUzpA1yGLLicYAiLhqM6nA4YDKZ2Ikql8sIh8MIhULIZDKnhtPwOFA5zGAwwOVysaNLqXoArGxPukObm5uIxWJd50W1y3SQVAfNKuvr64PBYIDX64XFYoHL5YLX6+UsG+mhEKE8mUwiFothZWUFy8vLWF5eRiAQQKFQ6KpNwKeZWyJdU1esTCZjHolWq+WD5CDlVMpYUnai3Rmjz7OX+G0UFQeDQeZNjY+P80BmnU7HZR+DwYCJiQkWEj7p9vKngVTqiUvTLtXxJNAzSoEDZeiINHzhwgV2klUqFdMnqtXqkfdxyn7Rnmiz2dDX14fx8XGMjIzA5/NxiY6wV8mN1i2VeCib1Gg02CGiDGOlUuGfHRwc5Pek/TcYDCIQCPAsu26CKARarRYGgwH9/f0wGAzs4EWjURYwNhgMXLI8CQ0+ylpSN75KpeJ9kECVBtKIXFpawubmJoLBIFZWVpDJZLiTlGQntFotZ5UqlQpyuRw7UzQyzWKxwGg0Ynh4mOVzyuXyruD8SLYd+R2OEe3pvke/joL2+V42m40jEYVCwRL7i4uLzJM4SZAo6cjICMbHx3dxo5aXl7GysoK5uTmsr68fW2tntyCRSGAymdDX14cXXngBX/3qV3HlyhXYbLZdJb1qtcrjZm7fvn1ielkajQZqtRoDAwMwm80YGBjA8PAw+vv7MTExAaPRyNdO3Dvi/1WrVeRyOQSDQeYeBQIB3LhxA/F4HNFo9ERmmxGpk4bVfvDBB8jlcnjxxRcxOjqKb3/72+zkffLJJ4jFYtjc3ESlUtnXIbKzs4NMJsOTCTKZDJfW1Wo1jEYjSqVSz5C1yfErl8t8vYFAgDfmsbEx5swQN4MkBdoP816FXq/nLqn9ZCmoq21oaAhutxsDAwM4f/48vF4vLly4wLaTU2I2m2EymfD2229zc8hhS2DkQNFnPzExgYmJCZw/fx6XL1/mYfT0u9sH9NK4HgJRO27evIlsNotUKsWlTBLXXFpa4kDilVde4VmENKYsEokgGAzi7/7u77CysoKVlZWuB7JqtRparRaXLl3C0NAQfuZnfgbNZhPvvvsu3n33XSSTSUxPT0Mmk8Fut0OpVLID0+2gpd35JUHsR5HL5RCNRvG9730PGxsbuH37NorFIpfu2jPYJIBMuntyuZypOhTstY8Vo4C8XC5DqVQil8uxGsBR0dOOFHA8/AnyWqn7r1QqcTRst9vhcDj44DtpyOVy5h14PJ5dHjxpJ5HUwUnX6I8C2iRtNhtvztQKS2XMWq3GXZsrKytYXV1FOp0+ULt9J9C+VqisYLVaMTAwwFlUr9fLhyo5UO0olUrY2NjAysoKAoEA7t+/j2g0yl03J0WaJ8ehVCohlUphc3MTSqUSIyMjPBGgVqtBp9OhWq3C6XRCr9fzkF5q/69Wq5+5flqfzWaTBS0pI0cisx6Ph3kLyWTyM+NYTgqUoSuXy5zhWF9fh1wux/DwMGfRaTM3Go2nwpFq1+jZT4BKjhKNHRkdHcXExAQcDgd3SLVTJKhDdXBwEDs7O8hms9x8clCQVIjP54PT6cSFCxcwNDSEkZERWCwWaDQazhQVCgUul1O2qJ32QGuPBvzS/9H6rFQq3IFHWQ16JslRo+d2Y2MD4XAYlUql64EsrTer1cr0ge3tbaysrCAWiyGfz/N10z2hkiwR5bsJ2gsfd7aWy2Xm17ZPRGhfm49q80kkEjgcDuj1ejidTjgcDlitVoyPj/MerdVqd2Uz6TPoVJNLTztS7Z7no19HQTabRb1ex9LSEgwGA2KxGHdhjIyMoFKpQKPRdP2A3guUOp+amsLZs2d3jSQIh8OYn5/nSPk0KyxTaWxqagqXL1/GG2+8sUtPpNFoIJvNYmlpCTdu3MA777yDzc1NRCKRrmcNqdw6NTWF6elp/Nqv/RocDgecTucubZMnIZFI4O2338bHH3+MxcVFBIPBXR03J+k4EHekXq/jxo0biEajPJ7H4/HAZDJhZ2cHg4ODrEZOjhTJXyQSiV2bNB1OlUoF8Xicna9cLsflBo/Hg9nZWd5k3333XeaI9QKXing11B30/vvvI5VKcRNE+6DV/v5+rK+vn+j1dhoSiQRerxcDAwP4yle+gpGREUxNTfFkBeocKxaLnIV1u92QyWR45ZVXoNVqOQt7GIfDYrHA6/Xi9ddfx/DwMK5evQqj0cgc11arxe3xgUAAy8vL2NzcxDvvvINIJILNzU1ek/SMEUl8r71TKpVCr9fDYrHw4Qt8OlLoo48+wj/+4z9ifn7+RDS3iEuq1+vh9XoxNDQEn8+HpaUlXLt2DX6/HzKZjAMYqrqQ5I9Sqex61ps+d1orjzpyuVyOp5VIpVJYLBbORmUymc90f1M26sqVK1xWdrlcsNvtsNlsUCqVrE/3aDark/tJTztSxwWaW5ZKpRCJRLC2toaRkRGo1WpuVT/pdmzqnqLNw+VywWq1QhAEnqlHbayHmV3XC2gXVbPZbLDZbDh//jzGx8dhMpl21a+JgOj3+7G2tsYlMSI9dxO0gT333HN44YUX4PF4oNVqD9RuTc0UtAnOzc0hmUyyQ0WZj5MC8Q1CoRAqlQquXbsGu93OhHki9Gq1WtjtduY90TT5VCq1i/sEPIg2q9UqYrEYjEYj7HY7DxDXarUYGBjAiy++CJlMhlarhaWlJR4dc9LOZTsoa0cyAe3ile2igb1yvZ2CRCLBxYsXMTExgbNnz8Jut0On07GS/fz8PHK5HGKxGM/EvHz5Mmq1GmcCjrKver1enD9/Hi+++CLzDZVKJVqtFndif/TRR4hEIjz5IhaLYWNjgwWcCe0H+l73SS6X83ofGRnB+fPnMTw8zBlS6qJt51d1EzKZjCsVXq+Xu9Ko3Oj3+6FQKGA2m5lfSpke6rbtJS4iweVyQaPR4Bvf+AaKxSI7Vul0mukr5PwRyV6n0+Gnf/qn4XQ6eTgzNf08ysE6Lpw6R6r9QTzsA0lpeiKdh0IhOJ1OjiypfnySoEGxJpOJ0+ZGoxEAeM4SlYLIYz9taJ9dZTab4Xa7edJ3+6w5KhUlEglWbo/H4yc25oAiu/HxcVy4cAFWq/XAmjUGgwHnzp2DVCqFyWTiWW+lUglSqZQdxJM6jOl3k3bV7du3YbVaEY1GMTIygr6+Pr5POp2OX0clkPap8lQ+Ih5VIpHgkgRNLaDunZmZGchkMjQaDXayjoPL0V7Oouvc7++g19BGT4d0u6p5t2ciHhZ7ra+9nB0imJMTReNIZDIZB6Tvv/8+IpEItra2MDIygqGhIYyOju7iBx4lOLXb7RgbG8PU1BQcDgdzRakhIJVK4ebNm9ja2sLc3ByPTyHttYNkNWUyGSwWC/r7+zE9PY2xsTG43W6Uy2XOjhcKhRMTuKTGD6vVykG2Wq3mbuZEIsHioSQvQIO2i8XiiewtT8pEESwWC5eD6TmiQeG3b99GLpfjpgXSLtPr9Sx7QQTz/Y6V6RR60pGiD7xWq+3iigiCwK3kLpcLuVwOKpVqX2Ni9vod1WoVxWIRyWSyZ8itwKdlrjNnzuDcuXN46aWXYLfbeRbW1tYWfvjDH+LOnTsIhUKnkmROnSZutxtDQ0N4+eWXMTQ0hNnZWe6kJP5MKBRCNBrFW2+9hcXFRSwuLnJ59iRAjjjpPZ07d46zmfsFjUBq7wDLZDKYn5/H8vIy7ty5g/n5+RMdGkvE80qlgps3b7Lz4/P54PF4MDExAYPBALPZvEsCgv6kYIT4GJRlpcOVyOXU/UVjOILBIMLh8K7nv1ObviAIPI+MumBjsRiy2SxCodATVclpY7bZbDAYDNwlRoNSZTIZH1SpVOqpA5t7AcVikR3BZrPJvD69Xs8OrFQqxZkzZzA6OoqLFy+iv78f9XodgUAA29vb+Pjjj+H3+zE3N8dZj1qtxjICneKaUkmdMtX5fJ7FiO/fv49gMIh/+7d/QzqdZoX5wwYkNNfUbrdjcHCQxXL/5V/+BeFwGEtLS9wV1+39l67N5/Ph3LlzmJqagtVqRbVaxXvvvYd79+6h1Wrtcjp3dnawtLTEUjknIdVQKBSwtLQEh8OBVqsFp9P5GR4h7RnUNNBqtfhZdTqdXIptD4TkcjmrorcHtN2sKPWkI0Wq1dlslslywKdZGqpbU3nhsNFfeyt2L0WPpILtdrvR19fHxGUAXNZbW1tDPB4/dqXr4wLpzzgcDvh8Pp7j1k4arVarPNYnEAgwqTObzXZl3tzjQI4UiYFSOrp9U6A1RZlCOsDpUKHuPfoclEolzGYzR7e5XA6hUOhEWqrbQaUqGstAulIUmVPXl0wmYz4CDV+mqJAIriR4azKZeISHWq1mxWPaFGkuWLFYPFSQ9CTQ77BYLEyW3tzc5HEo1LTR/kyRDXSIOxwO2O12TE1Nob+/n8sqpLdFGZJezxK3Wi12diqVCgRBgFarZbVztVrNXBW3280De7VaLcrlMhKJBNbX17G2toZAIMCldtICIie42WxyWfcojQPlcpmzX7Q3BINBrK6uMs+Q1s1hslAEWiM09sVqtTIHjLq9FxYWmA/Y7WYIohZYLBbugKvX60in01heXkY6nYZKpYLdbucqC1Ux4vE4UqnUieyf9Xqdu/L8fj/i8Tjkcjl0Ot1nMkiU9SVVedor6X4++rNKpXJXxrPbtJyedKSq1Sqy2Sw++eQTVCoVnmtExGtBEFj0LZvNYm1tDdls9mQvukOgzijii5w7dw6zs7MAwIf34uIi3nrrLe6AOW0kc6rvj42N4cKFC7h69SpeeOEFuN1unrPUarU4S/Dv//7vWF9f51b8k77XJEz53nvvYWtrC8lkkgnTwIMDKpVK8UZPqeaJiQkmxqrVau4oIY0XIs5SejubzUIikfCcwpNGe7dSMBjEnTt3eMMiB4s618gxAj7NSJFw48DAAGeDaPi2wWBgYdIPP/wQb7/9NlZWVjpevqVgbHx8HC+++CJee+01zM/PIxAIQK1W87ghKtuQE0j3xm63Y3Z2FoODg/jSl77EpZX2z4da60+DIxWJRGC1WpFIJKBUKuHz+fDcc8/BYrEgmUwyV++5557Da6+9hqGhITSbTdy6dQtzc3P4yU9+grm5OS4BU8lJr9fDZrOxA0KNIUcR5VxcXEQ+n0cmk4HJZIJMJsPm5ibm5+d5NBbJGBzF+abghppJpqenuTRGQ4q3trZOJJCjKRdWq5WDT7fbjffffx/Ly8v4l3/5F1itVgwNDWFychKTk5MAgFQqhTt37mBxcREbGxsnEpzRSK/FxUUUi0UW53z55ZdZb2wvkBOlVCr5e+RI9UoC5KmOlCAI/QD+GwAXgCaA77RarT8XBMEC4P8FMARgE8CvtFqtdCcuiqTeFxYWAAA+nw+Dg4NwOp28yAcGBpBOp5l0fJiWWtokS6USfud3fofbzl9++WUAn+VMCIJg7pSNe4EiX2qf7+vr444RivDS6TRHQsTJOC1oH/1it9sxPj6O4eFhzri189KazSZHL5ubmwgEAmg2mxyJPQrqFqJWWdJLadeuefjgHbnOQFF2PB5Hs9nE3bt3d2WkyAksFovcQi2TyVAsFnfNf7JYLOxMjYyMcEmFMq7keBw0ujrudbpXqY0+352dHZY2aE+/SyQSZLNZKJVKZLNZbqOnjsypqSk0m01sb2/jL/7iL1hH63GH1VFspLVSr9chk8nQ398PvV6PdDoNm82GVquFaDSKbDbLJUjKDA8PD2N6ehoej4fnfJEuWLVaRTKZRDKZPBUNIMSBo65fu93Og5nlcjmCwSBndkZHR+FyuSCRSFAoFLC9vY1gMIhIJMKfJVES7HY7VldXsbS0hHfeeQdf//rXORuSSCTa9+kDPYu5XA4SiQQLCwusG0TkaiL7H9WJkkgkuyYRkKI5BaxULtyvE9XpZ5HKeuTU63Q6yOVyblCRy+UYGBjAq6++ir6+PigUCmxubmJ9fR3b29tc8uykE7hfG9sFscPhMO7evcvUBQogKVtNyvTtZWES8C2Xy7uyxjSSjGbnURadJBG8Xi9dZ/s1dzRrtZ+MVAPA77darU8EQdAD+FgQhH8F8D8DeKvVav2JIAh/BOCPAPxvnbgoSgF/8sknKBQKvCAoKpTJZBgbG0OpVEI8Hmc9oYOUuGhzJ2n9P/zDP8Qbb7yB27dv4xd/8Rc5ff0IOmbj465JLpejr6+PW1mtViskEgmLg1Jqtl3X5LSAyOUOhwP9/f04d+4cxsfHMTQ0xKVL4NOSKznKq6uriEQiPJx0LyE3Ev+j+Vibm5twOp3IZrPcuZJKpZDP511HtYMcqUgkgnQ6zcOvKaIi5420kGithUIhJtFT+cvlcsFms2FnZ4c74mgwLmVhD/HAH+s63QvkXFGk+zTpEGrD1mg0aDab+PKXv8z3/fLly3j33XeRTqefFBwdykZqeScScqvVwsDAAAYHBzn712q1oNFoEA6HefjpzMwMJiYmcOnSJfh8Pt7w6d5Q2300GkUkEkEqleoJ+ZQnodVqsY2JRAImkwlms5n1d4jnVK/XMT09Da/XywT71dVVrK+vIxQKcZaJhm+PjY1heHgYr732GtxuN37u534OXq+XB8a2NQ8c6FnMZDLI5/MoFov8vOXzeSSTyY4QvimQdTqd6O/v52wPzXKr1+vMGTwAOvoskmgxZUINBgM7UpVKhQc3/8Iv/AI7+IuLizyLlRypDmNfNhJlh8roH330EVZWVhAOh3fJN1itVng8ns9oOZI4aiKRYLkVAMzXI11F0vMiPp/H4+FKx3GV/J7qSLVarTCA8MO/5wVBWADgBfDzAF59+GP/D4B30KEF084TWVtbwz/8wz/w5G2tVst/9/l8yOVy2NzchFQq5YnW1WqVvdK9QAc6dcRdvHgRIyMjAB7wk9xuNxKJxF6p+a93ysa9oNVqWS15amqKSY5UL6aW9E5HFN0Cqcv+1E/9FEZGRvDiiy/CZrPBbDbv6RzRGBidTseq4cTJeRq+973vYXZ2Fm+++SZ+8Rd/kUcCvfPOO+anvngfaNeg2d7e/ox+1F4cKeKbAJ9ypKikZ7VaUa/X4fP5AIA7chwOx2E6SL+OLjtSR0E7r8HpdMJut+/6/mPwdRzCRspGLSwsYHJyEqVSiXl5MzMzGBwcxNjYGGeVKNCi0RukjiyXy3e1zweDQWxubuKHP/wh1tfXMT8/fyocqVAoBIlEgsXFRQ5yaDzXF7/4RbbPbDZDoVAgHo9z9K9SqbijGAAHgD/1Uz+F4eFhOJ1ObG1tcelwDxmLAz2LdC2ZTIb5MPScdWI/JO2hl19+GcPDwxgeHobBYEChUGCpmbW1NR5Rsk98HR16FqnVf3p6GlNTU5icnOQGpFqtBqvVit/93d/F9PQ0+vr68N5772FtbQ1vvfUWotEoAoHAcSmvfx37tJGCrXq9zqNfiGc6MDCAsbExPttJwoBA3LdgMMhNEgC48SeTybBcC9Fd6vU6rl69euxd+AfiSAmCMATgIoDrAJwPnSy0Wq2wIAiOx7zm2wC+fdALow88nU5jdXWVH+BGowGFQsGkSI/Hg4GBAVQqFRSLRY6YKP261wNGmiYkHU9kQgA8JNFisezliHXUxkdBXUwOhwM2m40JrPR5UBdVt+vbnbKPlGdHRkYwOjoKr9fLs8r2AjknTqcTgiBgamoKBoNhz9JeO+LxONLpNF577TV8//vfx+zsLBYWFijrteeaP4yN5KzTPLz2g3+vdbdXl2E+n0c2m0U0GoXD4eCfIZ4RkbYPiGNdp53Eo+TSdjzlcDy0jY1Ggx0l6laTyWTMVzObzUzAJoJ5+8zP9vehck8sFsP29jZWV1eZN3ccwU4n7yFJOKTTaYTDYTidTiSTSbhcLh6t8eiaJqdFrVbDZDLB7XYDAJeUfD4fxsfHYbPZoNPpcO/ePWxubsJqte4Sw3yIAz+L7VnPTsNgMMDtdmN4eJgbX6RSKQvMRqNRJJNJPsD3iY49i9QNS13rdrudmwXUajVUKhWuXLkCu90OQRAQCoU4E0XZvGMKwA9kY7uwLQCeTkEOECUxKGNNoPPd7/ezHhbw4DkMhULI5XLciNBqtVgipxtJh307UoIg6AD8DwD/sdVq5fabImu1Wt8B8J2H73Egi+jBrVariMfj8Pv9cDge3DONRgO73c6DYqPRKK5du4bt7W3Mzc0hlUrtcqiIOyORSGA0GmE0Gnl20tTUFEc6f/AHf4DXX38d169f3/cNOIqN7ejr68P09DR8Ph9cLhdvYq1Wi1Wg79y5g9XV1a52Gh7VPvrcZ2dncfXqVXz5y19mZ3EvJ4HanGdnZzEyMsJcFhpB8SSZgUKhgK985Sv48z//c/zcz/0cfu/3fg/nz59HoVB4Yhv2UWykkqxarWaOBmVFn7aG6KHPZDLIZrMol8tMzPZ6vchmsx1rH+/UOu0kKNihr/bD9jCk5P3YSL8nk8lgc3OTM6LENzEYDNDpdLxnUMmnHfT6eDyOxcVF3Lp1i0Ug0+n0sW3enb6HJJ567do15jA9//zz8Hq9cDqdu543QRBgMpkgl8vxy7/8y7ukImhf1el0LCmxtLSEP/7jP4bX60UwGOz6fnpQjI2N4erVq3j11VfhdDpZN21zcxMffvghVldXsb293ZFml8PYaDAYYLfbMTo6iuHhYbjdbu6Q/KVf+iUADwQtV1dXce3aNbz55ptcOut09+t+sF8bm80mEokE0uk0tra2mD8ql8t3BdnVahWVSgXpdJr/TmjnS7VarV0dfg+vZdefj/79qNiXIyUIghwPnKi/abVaf//w21FBENwPs1FuAAfKd+4XVB4JBAK4d+8eXC4XGo0GPB4PdzA4HA4olUrMzMzAZrMxHyaXy3E6kwYVqlQq9PX18diVvr4+yOVylEol/Pqv/zouXLgAi8XyuEnlx2Ijob1FnByMRqPBEXQ4HEYwGOwYJ6AbEB6qz5LUgcfjgdFoZCXwJ72u/WdId4q6w/ZCvV7Hb/7mb+I3fuM38Cu/8itIJpMwm8346KOPsL6+js3NTeAB568joIwZ6SDRuqGZgPV6/anOQLs8QAfbd491nXYStI7b1zLNZHuKEOeRbCTndXl5GSaTCdVqFX19fTw640kCkvl8HoVCAYuLi4hEIrh37x7W1tawvb3NxOvTAtpfE4kENjY2IJFIoFQqkUqlmJPYXkqn/7darSz1AOyW9yiVSlhdXcXv//7vw2QyoVarPS6LdOKtqO3SFjabDW63m8u3Ozs7yOfziEQiCAQCCAQChxkF07Fnka6TRryQnhadg9VqFeFwmDsZQ6EQMplMN6Y/HNlGyu5TmZKaVtqVyWk/pcay/T5nx+1EAfvr2hMA/FcAC61W6z+3/df3AXwLwJ88/PP/6+iVPQSlzz/44AOsrKxAp9NhcnKSxwMoFAq4XC44HA709fVxGjaXy6FQKOCf/umfEA6HEYlEYLFY4Ha7cenSJXi9Xpw5cwZ6vR6tVgu//du/jdHRUUilUhaW28OROhYbCdSl0O4skF7K0tISlpeXcevWLW7xPQ2OFG3GIyMjGB4ehs/nYxHGJ0EQhF2dcE9zMFqtFn7rt34Lk5OT+L3f+z3k83ksLCxgcHAQf/Znf4ZqtYpoNAoAmU7YRVko0hUym80YHR1FJpNBLpfjMRJPc6SoK4xspcnylPo+ZEPBsa7TTuDRLFR7JurHP/4xb6BPcKSOZCO15P/oRz9CPp+Hz+fDSy+9BIvFwt1pjyupbm9vY3NzE3//93/PM92oNNHOzzgNoFJZIBBAJBLB3bt3sbS0hKGhIUgkEvT19WF4eHjXa+RyOaxWK7+eQPyzra0t/OEf/iET+p8g0ZI5PsueDnKiKANCumJ0thDnZmFhAXfu3MHa2hoKhcJBn8eOPYt0PigUCsjlcuaV0n6RTqdx48YNzM3N8aicLjn2HbORCOWnQcy2HfvJSL0M4DcBzAmCcPvh9/53PHCgvisIwv8CYBvAN47lCvHgYS2VSkgmk/jggw8QDAaRy+U4w0HDCUmUi9LM1WoVr7/+OnK5HHK5HHfgkC6VwWCAVCrFW2+9hb/927/FyMgIEokEl2X2OLT/5LhsBD7taqDNJ5vNIpvNIh6P4+7duzzL6rSQzSlb4/F48Morr2BycpLJrPspV+3Volqr1VCpVFjwkFK87733Hv76r/8abrcb3/ve99BqtXDx4kUoFApWrH74mYWPahc5ujSa4Qtf+AJcLheGh4c5M5HJZHjdPmoTRZESiQR2ux0OhwMDAwNwu93QarUoFArI5XLw+/3Y2Ng4zMF8rOu0E2gX3aW5kTKZDO+++y5WVlZY3PIJOLKNNNz2448/xvb2NneuOZ1Olp5wuVxM6E2n04jFYtxFev/+faRSKaRSKc4cn5YAZy/QPaHMy1/91V8xwf5RPI7TVqvVmGzfPjD3MTjys3hY0PNHjSxf+MIXcO7cOTidTiiVSuzs7CAejyMUCsHv97MS+CHubceexUajgWq1ilQqhWQyyYLMhUIB169fRzAYxO3bt+H3+xGLxVgmoAvo+f3muLGfrr33ADyuzvDlzl7O40EtjTRDaWdnBz6fjwditnfT0KgJ4AGXitKARDKnMRY002t6eho/+clP4Pf78V/+y3/B+vo6otHoXhvFsc7roFQ5dSRkMhkeZLu8vIylpaVTMw6GnCCFQgGLxYKZmRn09fXBaDTuKl0+De0EV+CBunE2m+URHEQ63NnZwbe+9S2srKwAeLDprK+vI5/Ps3P98HM70s5CUaxSqeQ26atXr3LXCfFJDAYDq4HTtZMDRfMcKZtFLbo0MoHGjMRiMUQikQNvhse9TjsB4jOQgxKNRpmw/Ku/+qt48803ebjqY15/ZBvL5TLi8Th2dnYQDAaRTqdhMBhgs9m4G21ychJyuRypVAp+vx/Ly8vw+/1IpVLY3NzkoOe0Ok/toMxgPB5HMpmE3+//jJbP00DPq1Kp3I/i94ml7siRUqvVcLvduHr1KmejSLcvlUoxybx9WO5B0Mlnkbq2yXmPxWIcdN29exfb29uYn59HOp1GJpPpJoe25/eb40ZPKpvvBYqWgsEge+SkpUHaEyQkJ5FIMDk5if7+fthsNgCfpqBJoTafz7PDtLy8jM3NTe5yyGazJzJ09GHpiUdvmM1mFAoFpFIp3Lp1C9Fo9FQ4UcBuXaFwOIxr166xUKZMJuMy1pNeT50mS0tLPA8sk8nwmAjiqpAQWygUQjKZ5NdThqBTxHziaQ0MDGB8fBw/+7M/i7GxMYyOjiIWi+EHP/gBbty4gfn5eayurvIBS5s2ZTlmZmbg8Xhw7tw5Fv3z+Xw8KuHzAHKOt7e3UalUeD00Gg2sra3xMNjjBK2PSCQCqVSKRCLBcgcmkwk6nQ79/f2QyWQ8143EH2lO52nhKh4EtPeRA38Qvl47H6WXPxd6Jikgeu6552A2m1kAt1arIRwO85zPXpjFWiwWIQgCbt68Cb/fj62tLQ4mr127hmQyyZMATpNQ87OAU+NIAZ92r1GkUyqVeFMzm80ol8tQKBRM2ia9qEc3AjqgV1ZWEIlEMD8/zwrp+Xz+xOa40QDljY0NVneliJcE/np5c3oU5MyQEvLm5iZMJhNaDwUP5XL5nps0bcKpVAqZTAaLi4us5p7JZDiDQe2wFKllMhmurT/aDdYJ0MZrt9sxMTGB0dFRFmckPgiVhWkOJHEaSANGr9ezzsvZs2fhcDhgMpl4Xl2xWEQmk2GeH43oeBbRarVQKBQgkUiwvLzMmY9ucQDbOVqkCUb3oFQqQa1W85gYklWhAeenvYz3NPS6I3RUtDtSGo2Gn79Go4FUKoVoNIrt7W3EYjHmPJ40Go0GyuUywuEwC3CSMCWdXb3g8PUa9uLXdlqY81Q5UgCYgEsDLIPBILa3t3l2GXU/3bx5kyUEHo3ySSOmXQ2VDuqT3DwoJbu9vQ1gNw/hNEYYrYeilfF4HDdv3kQul8Pc3BysVitnph4HKvsQeZWcFNo4yOFtJ2Mf972TSqUwGo04c+YM3njjDQwPD3M7uMFggM/ng0wmY6Iu8cMsFgscDgfPnDMajTxOg8rNwIN1ubKygrm5OVy/fh03btxAKBTqiU38uJBIJJBMJrG1tcXfO6ksT/veksvlAAAbGxv8/8+6c/F5Ak21sNvtXM7LZrPI5XL44Q9/iLW1NfzkJz/hkT+94KAQEXt+fh7AbmfgNDU4dAvtg5BJ2Zx8gZMYEdOzoEiyvWWSPrxyuYxAILDn64gzRbo9J5mFehTP2mZNXJhyuYxgMIhCoQCdTscO7+NAbdmPSgk0Gg3+/kmUX6nLR6/X8wgD6jD0er1Qq9VMUFYoFDzqxWw27+JXEUeKCKSRSATJZJL1iKjEfFoaC44CWiO9hG455yJOBnK5HFqtFsPDwzxChPapSCSCcDiMRCLB81d7aR2cxqD6JLDX50Q+A1F5OiUNcaodKXI6SCeKokgA8Pv9J3hlItpBG5Tf7z/V96V9PiPN/CNnkDZlr9fLo2CkUik0Gg3zbtrfh0ADupeWluD3+/HjH/8Y29vbWF9fZ0dKhAgRnQVlhM+cOYOhoSEu65VKJdaNSiQSp24wvIjdeJTiQZMIFhcXsbGxgXK53JGM/6l2pESI6CaI80V8LIPBgGazycJxRqORy8bEq0gkEntqEtXrdRQKBUQiESQSCdy5cwfRaBQLCwvIZrPIZDLPdElPhIiTBB2qtVoNmUwGCwsLiEajPAaGNOBEJ+rZQDtFplqtYm1tDX6/v2O6b6IjJULEAUDOVLVa3fUAUqaKeFvkcD1ucC2NOvD7/YhGo9jY2EAikUA8Hke5XN5rYLYIESI6jJ2dHX4W0+k00z3ETNSzg/YyfbPZRKPRQDabRaFQ6Bg9ROhm7VcQhDiAIoBE137p4WHD7uscbLVa9qe96Fm38ZTZBzz7Norr9DF41m085fYBz76N4jp9iGfdxq46UgAgCMLNVqt1uau/9BA4ynU+6zaeFvuAZ99GcZ0e32u7CXGdHs9ruwnRxuN7bTdxmOv8fKj/iRAhQoQIESJEHANER0qECBEiRIgQIeKQOAlH6jsn8DsPg6Nc57Nu42mxD3j2bRTX6fG9tpsQ1+nxvLabEG08vtd2Ewe+zq5zpESIECFChAgRIp4ViKU9ESJEiBAhQoSIQ0J0pESIECFChAgRIg6JrjlSgiB8VRCEJUEQVgVB+KNu/d6nQRCEfkEQ/l0QhAVBEO4LgvC/Pvz+fxIEISgIwu2HX1/bx3uJNp4QOmVjr9oHPPs2iutUtPGR9+lJ+4Bn30ZxnR7Mxs/MojmOLwBSAGsAhgEoANwBMN2N372Pa3MDuPTw73oAywCmAfwnAH8g2vj5sbGX7fs82CiuU9HG02Df58FGcZ3u38ZWq9W1jNRzAFZbrdZ6q9WqAfjvAH6+S7/7iWi1WuFWq/XJw7/nASwA8B7irUQbTxAdsrFn7QOefRvFdXogPOs29qx9wLNvo7hOD4ZuOVJeAP62fwdwyAs+TgiCMATgIoDrD7/1HwRBuCsIwl8KgmB+ystFG3sER7DxVNgHPPs2iuv0c2/jqbAPePZtFNfpU23smiMl7PG9ntJdEARBB+B/APiPrVYrB+D/AjAC4AKAMIA/fdpb7PE90cYu44g29rx9wLNvo7hORRtxCuwDnn0bxXW6Lxu75kgFAPS3/bsPQKhLv/upEARBjgcf5N+0Wq2/B4BWqxVttVo7rVarCeD/xoMU5ZMg2njC6ICNPW0f8OzbKK5T0caH6Gn7gGffRnGd7tvGrjlSNwCMCYLgEwRBAeCbAL7fpd/9RAiCIAD4rwAWWq3Wf277vrvtx34BwL2nvJVo4wmiQzb2rH3As2+juE4Zoo09bB/w7NsorlPGfmzsTtde6wEr/mt4wIpfA/B/dOv37uO6ruJBqvEugNsPv74G4K8BzD38/vcBuEUbn30be9W+z4ON4joVbTwN9n0ebBTX6cFsFEfEiBAhQoQIESJEHBKisrkIESJEiBAhQsQhITpSIkSIECFChAgRh4ToSIkQIUKECBEiRBwSoiMlQoQIESJEiBBxSIiOlAgRIkSIECFCxCEhOlIiRIgQIUKECBGHhOhIiRAhQoQIESJEHBL/P0ZO4YCxX+DnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take prototypes from MNIST (in the future they have to be chosen randomly --> shuffle?)\n",
    "prototype_images = [0] * 10\n",
    "\n",
    "\n",
    "\n",
    "for source_data in train_MNIST_transformed:\n",
    "    X_source, y_source = source_data\n",
    "    \n",
    "    for j in range(0, len(y_source)):\n",
    "        \n",
    "        if torch.sum(torch.Tensor(prototype_images[int(y_source[j])])) == 0:\n",
    "            prototype_images[int(y_source[j])] = X_source[j].view(1, 1, 28, 28)\n",
    "            \n",
    "plt.figure(figsize=(10,10)) # specifying the overall grid size\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)    # the number of images in the grid is 5*5 (25)\n",
    "    plt.imshow(prototype_images[i].view(28,28), cmap=\"gray\")\n",
    "    \n",
    "    prototype_images[i] = prototype_images[i].to(device)\n",
    "    \n",
    "    \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(fNet, self).__init__()\n",
    "        \n",
    "        self.restored = False\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, 5)   # 1st conv layer INPUT [1 x 28 x 28] OUTPUT [64 x 12 x 12]\n",
    "        self.conv2 = nn.Conv2d(64, 64, 5)  # 2nd conv layer INPUT [64 x 12 x 12] OUTPUT [64 x 4 x 4]\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5) # 3rd conv layer INPUT [64 x 4 x 4] OUTPUT [128 x 1 x 1]\n",
    "        self.bn1 = nn.BatchNorm2d(64, eps=1e-05) # batch normalisation\n",
    "        self.pool = nn.MaxPool2d(2, 2, padding=1)\n",
    "         \n",
    "    def forward(self, x):\n",
    "        output = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        output = self.pool(F.relu(self.bn1(self.conv2(output))))\n",
    "        output = F.relu(self.conv3(output))\n",
    "        output = output.view(-1, 128 * 1 * 1)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "class gNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(gNet, self).__init__()\n",
    "        \n",
    "        self.restored = False\n",
    "                \n",
    "        self.conv1 = nn.Conv2d(1, 64, 5)      # 1st conv layer INPUT [1 x 28 x 28]  OUTPUT [64 x 12 x 12]\n",
    "        self.conv2 = nn.Conv2d(64, 64, 5)     # 2nd conv layer INPUT [64 x 12 x 12] OUTPUT [64 x 4 x 4]\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)    # 3rd conv layer INPUT [64 x 4 x 4]   OUTPUT [128 x 1 x 1]\n",
    "        self.bn1 = nn.BatchNorm2d(64, eps=1e-05) # batch normalisation\n",
    "        self.pool = nn.MaxPool2d(2, 2, padding=1)\n",
    "        \n",
    "         \n",
    "    def forward(self, x):\n",
    "        output = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        output = self.pool(F.relu(self.bn1(self.conv2(output))))\n",
    "        output = F.relu(self.conv3(output))\n",
    "        output = output.view(-1, 128 * 1 *1)\n",
    "        return output\n",
    "\n",
    "\n",
    "    def calcproto(self, class_list):\n",
    "        \n",
    "        g_output = []\n",
    "        \n",
    "        for class_image in class_list:\n",
    "            g_output_class = self.forward(class_image)\n",
    "            g_output.append(g_output_class)\n",
    "        \n",
    "        num_classes = len(g_output) # number of classes (10 in Digits experiment)\n",
    "        num_features = g_output_class.shape[1] # number of features (128 in Digits experiment)\n",
    "        \n",
    "        prototypes = torch.Tensor(size=torch.Size([num_features, num_classes])).to(device)\n",
    "        \n",
    "        class_count = 0\n",
    "        \n",
    "        for g_output_class in g_output:\n",
    "            \n",
    "            prototype = torch.mean(g_output_class, dim=0) # calculating the prototype for each class\n",
    "            prototypes[:,class_count] = prototype\n",
    "                        \n",
    "            class_count += 1\n",
    "                    \n",
    "        return prototypes\n",
    "    \n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.restored = False\n",
    "\n",
    "        \n",
    "        self.layer = nn.Sequential(\n",
    "            RevGrad(),\n",
    "            nn.Linear(128, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 2)\n",
    "#             RevGrad()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.layer(x)\n",
    "        output = output/torch.max(output)\n",
    "        output = F.softmax(output, dim=1) \n",
    "        \n",
    "        return output[:, 0]\n",
    "    \n",
    "class hSim(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "\n",
    "        self.restored = False\n",
    "        \n",
    "        \n",
    "        self.U = nn.Parameter(torch.rand(size=(512, 128), requires_grad=True))\n",
    "        self.V = nn.Parameter(torch.rand(size=(512, 128), requires_grad=True))\n",
    "        \n",
    "    def forward(self, f_batch, mu_c):\n",
    "        \n",
    "        batchsize = len(f_batch) # batchsize = 10\n",
    "        num_classes = mu_c.shape[1] # num_classes = 2\n",
    "        \n",
    "        h_batch = torch.zeros(size=[batchsize, num_classes])\n",
    "        \n",
    "        for i in range(0, len(f_batch)):\n",
    "        \n",
    "            f_i = f_batch[i]\n",
    "            \n",
    "            fac1 = torch.matmul(self.U, f_i)\n",
    "            fac1_t = fac1.t()\n",
    "                             \n",
    "            fac2 = torch.matmul(self.V, mu_c)\n",
    "            \n",
    "            h = torch.matmul(fac1_t, fac2)\n",
    "            h = F.log_softmax(h, dim=0)\n",
    "    \n",
    "            h_batch[i] = h\n",
    "            \n",
    "        \n",
    "        return h_batch  \n",
    "\n",
    "    \n",
    "class SimNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.restored = False\n",
    "    \n",
    "        self.fnet = fNet()\n",
    "        self.gnet = gNet()\n",
    "        self.disc = Discriminator()\n",
    "        self.hsim = hSim()\n",
    "        \n",
    "        \n",
    "    def forward(self, f_input, g_input):\n",
    "        # f_input is batch of images\n",
    "        # g_input should be a list (in the future maybe change to tensor?) of one (while training --> randomly chosen) or more (while testing --> every from test_batch) image(s) of every class\n",
    "        \n",
    "        f_output = self.fnet(f_input)\n",
    "        prototypes = self.gnet.calcproto(g_input)\n",
    "                                \n",
    "        Regularizer = torch.norm(torch.matmul(prototypes, prototypes.t()) - torch.eye(128).to(device))\n",
    "        \n",
    "#         print(torch.matmul(prototypes, prototypes.t()))\n",
    "        \n",
    "        Regularizer = Regularizer*Regularizer\n",
    "        \n",
    "#         print(prototypes)\n",
    "                \n",
    "        class_output = self.hsim(f_output, prototypes)\n",
    "        disc_output = self.disc(f_output)\n",
    "        \n",
    "        return [class_output, disc_output, Regularizer] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_class: tensor(16508.7246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3863, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(9866.9590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3863, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(8306.8232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3863, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(6047.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3863, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(8644.2441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3863, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(6726.7007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(8650.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3863, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(7691.5952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(6098.9355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3865, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(5403.6582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3865, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(5896.1440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3865, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(2600.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3865, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(2348.9326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3865, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(4010.6101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3863, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(4515.5537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(1935.9691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3865, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(2360.3958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3865, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(2340.8955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3862, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(2190.9692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3868, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(2654.1338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3865, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(2265.7573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3867, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(3203.6042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3863, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(2681.3333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3866, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(1612.0654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(2002.1678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3863, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(1126.7725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3863, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(2040.6222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3865, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(1827.4658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(1790.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3869, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(1428.5507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3867, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(1186.9744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3868, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(1694.5184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3869, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(1549.1427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3865, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(1197.9098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3867, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(1072.4626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3871, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(946.3156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3869, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(884.2678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3861, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(1038.9722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3868, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(922.7595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3867, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(664.3683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3869, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(521.5792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3861, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(634.4808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3854, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(720.6993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3862, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(605.7138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3866, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(529.9441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(611.3517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3870, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(560.4652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3883, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(443.7211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3858, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(601.0854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(658.8098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3872, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(698.3979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3869, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(797.7288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3858, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(898.9560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3862, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(600.9447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3872, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(824.3485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3874, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(827.2688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3860, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(746.8453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3867, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(475.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3877, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(654.8947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3868, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(535.1819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3870, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(517.6147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3870, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(450.9417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3881, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(507.3904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3869, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(425.3198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3879, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(407.6681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3879, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(374.8616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3873, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(349.9936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3879, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(555.3582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3872, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(489.0722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3863, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(450.3656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3874, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(498.7587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3866, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(407.1571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3868, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(389.4445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3888, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(419.7147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3876, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(501.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3878, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(410.2744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3881, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(418.1931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3861, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(358.5919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(419.1976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3874, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(376.0650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3885, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(335.5527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3884, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(364.8842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3867, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(376.2980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3890, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(410.3777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(346.6380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3886, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(333.4677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(326.1156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3867, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(330.9676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3875, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(317.8103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3888, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(332.8871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3876, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(372.3243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3880, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(391.7711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3882, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(299.3352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3877, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(372.9237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3876, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(381.5403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3880, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(411.0968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3874, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(382.8386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3853, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(413.1990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3868, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(351.3893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3857, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(368.8664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3876, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(337.5070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3889, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(346.0492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3863, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(376.1510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3862, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(312.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3861, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(329.1461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3883, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(347.9959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3857, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(292.2930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3876, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(332.8424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3866, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(249.6538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3888, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(375.0934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(370.7177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3871, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(330.5906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3867, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(364.3384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3888, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(462.7331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3861, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(398.3537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3863, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(460.8663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3852, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(408.2821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3904, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(384.4412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3893, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(329.2941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3888, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(357.9770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3895, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(397.4568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3883, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(422.8486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3884, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(380.0141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3858, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(288.7627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(305.7209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3880, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(302.3040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3884, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(356.9431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3879, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(294.6338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3881, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(266.4780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3870, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(293.1589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3874, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(333.4095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3866, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(374.6944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3888, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(281.0584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3880, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(255.3997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3884, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(333.4030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3845, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(297.9280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3880, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(300.1964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3869, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(336.4133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3878, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(322.0694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3888, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(299.7780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3840, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(292.5169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3899, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(245.1438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3906, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(331.6924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3863, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(267.3110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3890, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(282.1396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3893, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(288.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3912, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(253.8517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3842, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(254.9471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3853, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(226.5240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3896, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(239.8764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3858, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(239.7252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3833, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(254.7924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3894, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(279.7009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3875, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(282.6682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3873, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(274.3017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3865, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(247.5307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3877, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(246.6246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3856, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(265.0922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(265.5747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3910, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(244.1855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3855, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(239.3482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3880, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(249.0952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3877, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(240.1072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3871, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(253.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3882, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(237.5303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3899, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(238.9020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3913, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(250.3349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3881, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(250.6870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3866, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(259.5882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3920, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(249.8575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3912, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(262.6591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3896, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(256.9791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3892, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(254.3889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3906, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(257.8947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3839, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(240.0337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3891, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(255.8882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3845, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(244.4394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3892, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(225.4616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3874, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(248.6927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3916, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(242.9151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3848, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(233.2809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3901, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(241.9340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3867, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(257.3388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3871, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(231.7205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3860, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(219.9963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3854, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(233.5515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3915, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(243.6238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3908, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(233.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3879, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(246.0657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3874, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(244.0488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3925, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(262.8596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3836, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(255.7128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3934, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(255.3149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3852, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(244.8448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3883, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(233.2452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3933, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(229.1987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3866, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(228.7258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3917, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(239.7364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3901, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(251.9360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3852, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(268.4623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3873, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(260.3723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3874, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(255.6453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3874, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(245.2957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3900, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(243.8720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3903, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(233.8796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3911, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(200.0720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3863, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(243.6552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3857, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(246.1815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3874, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(250.2731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(217.9804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3893, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(219.0877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3848, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(194.5733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3875, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(197.6898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3896, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(227.6478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3876, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(204.5451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3895, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(194.1676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3891, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(198.8799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3902, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(195.2041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3842, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(211.2566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3885, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(223.1050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3888, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(201.7167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3911, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(201.8639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3866, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(202.5949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3857, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(211.4440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3872, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(198.9974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3939, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(201.0440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3883, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(198.0597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3877, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(204.2994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3886, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(187.3402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3889, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(205.7037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3906, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(188.8299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3938, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(199.7716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3931, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(209.4894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3918, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(206.7780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3892, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(210.7436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3898, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(212.9318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3878, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(203.6785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3888, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(192.7626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3853, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(193.4048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3951, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(194.0076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3854, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(200.9082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3891, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(183.5236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3886, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(188.5921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3902, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(193.1867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3918, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(190.9561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3888, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(203.2736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3855, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(191.2069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3896, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(196.5755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3911, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(197.1151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3952, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(181.0599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3934, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(190.2780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3881, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(176.3362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3917, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(195.9782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3878, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(210.1281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3843, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(179.7764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3878, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(177.2739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3847, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(188.3317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3904, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(195.6918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3873, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(201.0697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3946, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(219.1519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3863, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(177.9978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3861, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(180.3811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3889, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(165.1605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3879, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(170.2106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3858, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(187.9133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3878, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(186.9145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3933, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(161.3544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3879, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(173.9594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3913, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(169.6266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3829, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(176.6030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3796, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(174.0919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3903, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(165.0779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3896, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(165.0622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3912, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(165.1103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3896, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(159.8673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.4012, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(166.0665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3848, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(165.5138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3834, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(164.8361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3931, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(158.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3890, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(170.0032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3880, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(171.6411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3890, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(172.5329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3903, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(166.2890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3876, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(170.7479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3809, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(162.3143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3840, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(164.4463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3913, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(158.1783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3852, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(176.1175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(169.6342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3934, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(154.1660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3883, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(167.7263, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3868, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(165.1714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3932, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(160.2608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3911, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(164.6938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3904, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(163.7899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3971, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(181.9642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3907, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(163.5793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3889, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(167.2792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3959, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(157.3192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3869, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(171.4295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3871, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(163.5155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3981, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(155.3572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3911, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(179.0107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3941, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(173.4167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3932, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(169.1477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(1.3836, device='cuda:0', grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-9379e3a11920>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[0msource_class_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_domain_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRegularizer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_MNIST\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprototype_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[1;33m[\u001b[0m\u001b[0mtarget_class_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_domain_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRegularizer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_USPS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprototype_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-99433dea1e97>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, f_input, g_input)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;31m#         print(prototypes)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m         \u001b[0mclass_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhsim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprototypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mdisc_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-99433dea1e97>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, f_batch, mu_c)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mfac1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             \u001b[0mfac1_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfac1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mfac2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu_c\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gamma_reg = 0.01\n",
    "lambda_loss= 0.5\n",
    "\n",
    "simnet = SimNet().to(device)\n",
    "simnet.apply(init_weights_disc)\n",
    "\n",
    "# optimizerSimNet = torch.optim.SGD([\n",
    "#                                     {'params': simnet.disc.parameters(), 'lr': 1e-3},\n",
    "#                                     {'params': simnet.hsim.parameters(), 'lr': 1e-3},\n",
    "#                                     {'params': simnet.fnet.parameters()},\n",
    "#                                     {'params': simnet.gnet.parameters()}],                                 \n",
    "#                                 lr=1e-3, momentum=0.99, weight_decay=1e-5)\n",
    "\n",
    "optimizerSimNet = torch.optim.Adam([\n",
    "                                    {'params': simnet.disc.parameters(), 'lr': 1e-4},\n",
    "                                    {'params': simnet.hsim.parameters(), 'lr': 1e-4},\n",
    "                                    {'params': simnet.fnet.parameters()},\n",
    "                                    {'params': simnet.gnet.parameters()}],                             \n",
    "                                lr=1e-5)\n",
    "\n",
    "loss_disc_list = []\n",
    "loss_class_list = []\n",
    "\n",
    "for epoch in range(3): # 3 full passes over the data\n",
    "    \n",
    "    num_batches = len(train_USPS_transformed)\n",
    "\n",
    "    for i in range(0, num_batches):\n",
    "        \n",
    "        MNIST_batch = train_MNIST_transformed[i]\n",
    "        USPS_batch = train_USPS_transformed[i]\n",
    "\n",
    "        \n",
    "        X_MNIST, y_MNIST = MNIST_batch\n",
    "        X_USPS, y_USPS = USPS_batch\n",
    "        \n",
    "        X_MNIST, y_MNIST = X_MNIST.to(device), y_MNIST.to(device)\n",
    "        X_USPS, y_USPS = X_USPS.to(device), y_USPS.to(device)\n",
    "        \n",
    "                \n",
    "        simnet.zero_grad()\n",
    "                \n",
    "        [source_class_output, source_domain_output, Regularizer] = simnet(X_MNIST, prototype_images)\n",
    "        [target_class_output, target_domain_output, Regularizer] = simnet(X_USPS, prototype_images)\n",
    "\n",
    "        \n",
    "        source_class_output = source_class_output.to(device)\n",
    "        target_class_output = target_class_output.to(device)\n",
    "\n",
    "#         loss_class = 0\n",
    "        \n",
    "###### 'Our' implementation of classifier loss as described in the paper ######\n",
    "                \n",
    "#         for j in range(0,len(y_MNIST)):\n",
    "#             h_jj = source_class_output[j][y_MNIST[j]]\n",
    "#             h_jk = torch.exp(source_class_output[j]) # this term explodes if softmax is not applied?\n",
    "#             h_k = torch.sum(h_jk)\n",
    "            \n",
    "#             loss_class -= (h_jj - torch.log(h_k + 1e-7))\n",
    "            \n",
    "# #         print(Regularizer) # this gets absurdly large?\n",
    "            \n",
    "#         loss_class += gamma_reg*Regularizer\n",
    "\n",
    "##### Cross_entropy classifier loss #####\n",
    "            \n",
    "#         print(gamma_reg*Regularizer)\n",
    "#         print(source_class_output)\n",
    "        \n",
    "#         loss_class = F.cross_entropy(source_class_output, y_MNIST) + gamma_reg * Regularizer\n",
    "\n",
    "#         print(Regularizer)\n",
    "\n",
    "        loss_class = F.nll_loss(source_class_output, y_MNIST) + gamma_reg * Regularizer\n",
    "\n",
    "        loss_disc = - torch.mean(torch.log(source_domain_output + 1e-7)) - torch.mean(torch.log(1 - target_domain_output+1e-7))\n",
    "\n",
    "        total_loss = loss_class - lambda_loss * loss_disc        \n",
    "        total_loss.backward()\n",
    "    \n",
    "        optimizerSimNet.step()\n",
    "        \n",
    "#         print(\"loss_class: \" + str(loss_class))\n",
    "#         print(\"loss_disc: \" + str(loss_disc))\n",
    "\n",
    "        loss_disc_list.append(loss_disc)\n",
    "        loss_class_list.append(loss_class)       \n",
    "    \n",
    "    \n",
    "#         if i == num_batches-1:\n",
    "#             print(\"loss_class: \" + str(loss_class))\n",
    "#             print(\"loss_disc: \" + str(loss_disc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "        9, 9, 9, 9, 9, 9, 9, 7])\n",
      "tensor([[-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00,\n",
      "         -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00, -2.3026e+00],\n",
      "        [-1.0665e+02, -1.5161e+01, -1.3637e+01, -7.4303e+00, -6.2792e+00,\n",
      "         -8.2585e+01, -1.3785e+01, -5.0252e-02, -8.5014e+00, -3.0718e+00]],\n",
      "       grad_fn=<CopySlices>)\n",
      "tensor([9, 6, 3, 6, 6, 0, 0, 0, 6, 9, 6, 2, 2, 4, 0, 3, 1, 6, 9, 6, 2, 2, 4, 9,\n",
      "        6, 2, 0, 3, 8, 3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "for test_batch in test_USPS_transformed:\n",
    "    \n",
    "    X, y = test_batch\n",
    "    [class_output, domain_output, Reg] = simnet(X, prototype_images)\n",
    "    \n",
    "    print(domain_output)\n",
    "\n",
    "    print(torch.argmax(class_output, dim=1))\n",
    "\n",
    "    \n",
    "    print(class_output)\n",
    "    print(y)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5726, 0.9883, 0.1414,  ..., 0.0374, 0.7231, 0.9661],\n",
       "        [0.2662, 0.5542, 0.1316,  ..., 0.9427, 0.6415, 0.9345],\n",
       "        [0.7796, 0.4761, 0.7930,  ..., 0.2161, 0.4227, 0.7010],\n",
       "        ...,\n",
       "        [0.8246, 0.6484, 0.1934,  ..., 0.2324, 0.9319, 0.5450],\n",
       "        [0.3054, 0.1861, 0.6735,  ..., 0.7878, 0.0370, 0.4387],\n",
       "        [0.3510, 0.5852, 0.9645,  ..., 0.3491, 0.5956, 0.2489]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(size=(512, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
