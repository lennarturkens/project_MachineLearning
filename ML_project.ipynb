{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_MNIST = datasets.MNIST('', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test_MNIST = datasets.MNIST('', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "train_USPS = datasets.USPS('USPS', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test_USPS = datasets.USPS('USPS', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "trainset_MNIST = torch.utils.data.DataLoader(train_MNIST, batch_size=32, shuffle=True)\n",
    "testset_MNIST = torch.utils.data.DataLoader(test_MNIST, batch_size=32, shuffle=False)\n",
    "\n",
    "trainset_USPS = torch.utils.data.DataLoader(train_USPS, batch_size=32, shuffle=True)\n",
    "testset_USPS = torch.utils.data.DataLoader(test_USPS, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the data according to how it is done in the paper. First interpolating so that images are 32x32 and than performing 'random' 28x28 crop\n",
    "\n",
    "p = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.RandomCrop((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset_MNIST))\n",
    "\n",
    "train_MNIST_transformed = []\n",
    "\n",
    "for data_MNIST in trainset_MNIST:\n",
    "    \n",
    "    data_MNIST_transformed = []\n",
    "    \n",
    "    images = data_MNIST[0]\n",
    "    labels = data_MNIST[1]\n",
    "    \n",
    "    print(images.shape)\n",
    "    \n",
    "    for i in range(0, len(images)):\n",
    "        \n",
    "        image = images[i]\n",
    "        label = labels[i]\n",
    "        \n",
    "        image_transformed = p(image)\n",
    "        print(image_transformed.shape)\n",
    "        break\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n",
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# just plotting a sample to have an idea how the dataset looks\n",
    "\n",
    "for data_MNIST in trainset_MNIST:\n",
    "    for image in data_MNIST[0]:\n",
    "        sample_from_MNIST = p(image)\n",
    "        break   \n",
    "    break    \n",
    "    \n",
    "plt.imshow(sample_from_MNIST[0].view(28,28), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "print(sample_from_MNIST[0].shape)\n",
    "print(sample_from_MNIST.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n",
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for data_USPS in trainset_USPS:\n",
    "    for image in data_USPS[0]:\n",
    "        sample_from_USPS = p(image)\n",
    "        break\n",
    "    break\n",
    "    \n",
    "plt.imshow(sample_from_USPS[0].view(28, 28), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "print(sample_from_USPS[0].shape)\n",
    "print(sample_from_USPS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(fNet, self).__init__()\n",
    "        \n",
    "#             # 1st conv layer\n",
    "#             # input [1 x 28 x 28]\n",
    "#             # output [64 x 12 x 12]\n",
    "\n",
    "#             # 2nd conv layer\n",
    "#             # input [64 x 12 x 12]\n",
    "#             # output [64 x 4 x 4]\n",
    "\n",
    "#             # 3rd conv layer\n",
    "#             # input [64 x 4 x 4]\n",
    "#             # output [128 x 1 x 1]\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, 5) \n",
    "        self.conv2 = nn.Conv2d(64, 64, 5)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "        \n",
    "#         self.fc1 = nn.Linear(128 * 1 * 1, 512)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2, padding=1)\n",
    "         \n",
    "    def forward(self, x):\n",
    "        output = self.pool(F.relu(self.conv1(x)))\n",
    "        output = self.pool(F.relu(self.conv2(output)))\n",
    "        output = F.relu(self.conv3(output))\n",
    "        output = output.view(-1, 128 * 1 * 1)\n",
    "#         output = self.fc1(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      ")\n",
      "torch.Size([32, 128])\n"
     ]
    }
   ],
   "source": [
    "# just trying to pass some data to see if it works\n",
    "\n",
    "fnet = fNet()\n",
    "print(fnet)\n",
    "\n",
    "output = fnet(data_MNIST[0])\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(gNet, self).__init__()\n",
    "                \n",
    "#             # 1st conv layer\n",
    "#             # input [1 x 28 x 28]\n",
    "#             # output [64 x 12 x 12]\n",
    "\n",
    "#             # 2nd conv layer\n",
    "#             # input [64 x 12 x 12]\n",
    "#             # output [64 x 4 x 4]\n",
    "\n",
    "#             # 3rd conv layer\n",
    "#             # input [64 x 4 x 4]\n",
    "#             # output [128 x 4 x 4]\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, 5) \n",
    "        self.conv2 = nn.Conv2d(64, 64, 5)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 1 * 1, 512)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2, padding=1)\n",
    "         \n",
    "    def forward(self, x):\n",
    "        output = self.pool(F.relu(self.conv1(x)))\n",
    "        output = self.pool(F.relu(self.conv2(output)))\n",
    "        output = F.relu(self.conv3(output))\n",
    "        output = output.view(-1, 128 * 1 *1)\n",
    "        output = self.fc1(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      ")\n",
      "torch.Size([32, 1, 16, 16])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (2 x 2). Kernel size: (5 x 5). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-d579b94349a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_USPS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0moutput_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_USPS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_g\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachineLearning_OldPy\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-71-7b922ea25222>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachineLearning_OldPy\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachineLearning_OldPy\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachineLearning_OldPy\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    415\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 416\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (2 x 2). Kernel size: (5 x 5). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "# again trying to pass some data to check if the gNet works\n",
    "\n",
    "gnet = gNet()\n",
    "print(gnet)\n",
    "print(data_USPS[0].shape)\n",
    "output_g = gnet(data_USPS[0])\n",
    "print(output_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.restored = True\n",
    "\n",
    "        \n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        output = self.layer(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (layer): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=1024, out_features=2, bias=True)\n",
      "    (5): Softmax(dim=1)\n",
      "  )\n",
      ")\n",
      "tensor([[0.4912, 0.5088],\n",
      "        [0.4911, 0.5089],\n",
      "        [0.4917, 0.5083],\n",
      "        [0.4909, 0.5091],\n",
      "        [0.4909, 0.5091],\n",
      "        [0.4917, 0.5083],\n",
      "        [0.4912, 0.5088],\n",
      "        [0.4913, 0.5087],\n",
      "        [0.4911, 0.5089],\n",
      "        [0.4920, 0.5080],\n",
      "        [0.4915, 0.5085],\n",
      "        [0.4907, 0.5093],\n",
      "        [0.4912, 0.5088],\n",
      "        [0.4915, 0.5085],\n",
      "        [0.4911, 0.5089],\n",
      "        [0.4911, 0.5089],\n",
      "        [0.4911, 0.5089],\n",
      "        [0.4914, 0.5086],\n",
      "        [0.4911, 0.5089],\n",
      "        [0.4912, 0.5088],\n",
      "        [0.4908, 0.5092],\n",
      "        [0.4911, 0.5089],\n",
      "        [0.4918, 0.5082],\n",
      "        [0.4911, 0.5089],\n",
      "        [0.4914, 0.5086],\n",
      "        [0.4914, 0.5086],\n",
      "        [0.4916, 0.5084],\n",
      "        [0.4912, 0.5088],\n",
      "        [0.4917, 0.5083],\n",
      "        [0.4916, 0.5084],\n",
      "        [0.4907, 0.5093],\n",
      "        [0.4916, 0.5084]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "disc = Discriminator()\n",
    "print(disc)\n",
    "\n",
    "disc_output = disc(output)\n",
    "print(disc_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "torch.Size([4])\n",
      "tensor([1, 2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "# try stuff cell\n",
    "\n",
    "t = torch.tensor([[1,2],[2,1]])\n",
    "print(t.shape)\n",
    "t = torch.flatten(t)\n",
    "print(t.shape)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
