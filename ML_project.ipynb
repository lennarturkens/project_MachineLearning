{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_revgrad import RevGrad\n",
    "\n",
    "train_MNIST = datasets.MNIST('', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test_MNIST = datasets.MNIST('', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "train_USPS = datasets.USPS('USPS', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test_USPS = datasets.USPS('USPS', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "trainset_MNIST = torch.utils.data.DataLoader(train_MNIST, batch_size=32, shuffle=True)\n",
    "testset_MNIST = torch.utils.data.DataLoader(test_MNIST, batch_size=32, shuffle=False)\n",
    "\n",
    "trainset_USPS = torch.utils.data.DataLoader(train_USPS, batch_size=32, shuffle=True)\n",
    "testset_USPS = torch.utils.data.DataLoader(test_USPS, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the transformation\n",
    "\n",
    "p = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.RandomCrop((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the MNIST data according to how it is done in the paper. First interpolating so that images are 32x32 and than performing 'random' 28x28 crop\n",
    "\n",
    "train_MNIST_transformed = [] # initializing the entire (batched) dataset as an empty list\n",
    "\n",
    "for batch_MNIST in trainset_MNIST:\n",
    "        \n",
    "    images = batch_MNIST[0] # taking the images from the dataset batch. this a torch.tensor of shape (32, 1, 28, 28)\n",
    "    labels = batch_MNIST[1] # taking the labels from the dataset batch. \n",
    "    \n",
    "    images_transformed = torch.zeros(size=torch.Size([32, 1, 28, 28])) # initializing the transformed images with the same shape as images (32, 1, 28, 28)\n",
    "        \n",
    "    for i in range(0, len(images)):\n",
    "        \n",
    "        image = images[i] \n",
    "        \n",
    "        image_transformed = p(image) # transforming the image with predefined transformation \"p\"\n",
    "        images_transformed[i] = image_transformed # replacing zero tensor (1, 28, 28) in images_transformed with the transformed image\n",
    "            \n",
    "    batch_MNIST_transformed = [images_transformed, labels] # transformed batch is simply a list of batch of images in [0] and batch of labels in [1]\n",
    "    \n",
    "    train_MNIST_transformed.append(batch_MNIST_transformed) # appending to the empty dataset list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQBElEQVR4nO3da4xUZZ7H8d+fiygoCBIQaVxHg6hBBW3RAFncKOASEhwv6xBjXEJkXozJjJkXa9gXY2JidONg9pWxjWYYo06MM96SySrRiTAGUVpbLoMzAmmlbWwuGvDG/b8v+jBptc//NFWnLvh8P0mnuuvXp+pJwa9PVT11zmPuLgA/foMaPQAA9UHZgURQdiARlB1IBGUHEjGknndmZrz1D9SYu1t/11e1ZzezG8zs72a21czurea2ANSWVTrPbmaDJf1D0lxJXZLelbTY3f8WbMOeHaixWuzZZ0ja6u7b3f2QpD9IWlTF7QGooWrKPlHSjj4/d2XXfYeZLTOz9Wa2vor7AlClat6g6++pwg+eprt7m6Q2iafxQCNVs2fvkjSpz88tkrqrGw6AWqmm7O9KmmxmPzGzUyT9TNLL5QwLQNkqfhrv7kfM7G5Jr0oaLOlJd99c2sgAlKriqbeK7ozX7EDN1eRDNQBOHpQdSARlBxJB2YFEUHYgEZQdSARlBxJB2YFEUHYgEZQdSARlBxJB2YFEUHYgEXU9lTR+fM4555wwP//883OzMWPGhNvu2bMnzDs6OsL8m2++CfPUsGcHEkHZgURQdiARlB1IBGUHEkHZgURQdiARzLP/yA0ZEv8Tt7S0hPmIESPCfN68eWF+++2352aXX355uO3atWvD/J577gnz9vb2ME8Ne3YgEZQdSARlBxJB2YFEUHYgEZQdSARlBxLBPHsTMOt30c1/GjQo/ps8bNiw3KzoePNHHnkkzK+66qowLzomffDgwWEeOe+888L81ltvDfMPPvggNxs+fHi4bdHqxgcPHgzzw4cPV3X7tVBV2c2sU9KXko5KOuLurWUMCkD5ytiz/5u7x6cUAdBwvGYHElFt2V3Sa2bWbmbL+vsFM1tmZuvNbH2V9wWgCtU+jZ/l7t1mNk7SKjP70N1X9/0Fd2+T1CZJZlb/dyUASKpyz+7u3dnlLkkvSJpRxqAAlK/ispvZCDM74/j3kuZJ2lTWwACUq5qn8eMlvZDNEQ+R9Iy7/18po0pMNE8uSVOmTAnzm266KTdbvHhxuO2kSZPCfOjQoWFe9BmAauaTiz5/MGrUqDCfM2dObvbQQw+F2xbNo69YsSLMV61aFeb79+8P81qouOzuvl1SfPYBAE2DqTcgEZQdSARlBxJB2YFEUHYgERziWgdFh1Nef/31YX7XXXeFeWtr/sGGRYegFp1qusjGjRvDfOTIkblZ0Wmsi8Y+f/78ML/ssstys4svvjjctsiVV14Z5tHhtVJjpt7YswOJoOxAIig7kAjKDiSCsgOJoOxAIig7kAjm2UtQNI9eNB+8ZMmSMJ89e3aYR3PZRYeYdnd3h/nbb78d5s8//3yYL1iwIDe77bbbwm2LDv0tOk32+PHjK77trVu3hvmHH34Y5l988UWYNwJ7diARlB1IBGUHEkHZgURQdiARlB1IBGUHEsE8ewmKjsueO3dumM+aNSvMo3l0STp69Ghutnv37nDbF198saq8vb09zEePHp2bzZgRryly4YUXhnnRaa6L8sgbb7wR5h0dHWG+b9++iu+7VtizA4mg7EAiKDuQCMoOJIKyA4mg7EAiKDuQCObZS3DppZdWlZ955plhfuTIkTDv6urKzZ555plw25deeinMN2/eHOaDBw8O8z179uRmn376abht0Tx70bH6hw4dys2KPn/w5ptvhnn0mEvF/2aNULhnN7MnzWyXmW3qc90YM1tlZh9ll/mfnADQFAbyNP53km743nX3Snrd3SdLej37GUATKyy7u6+W9Pn3rl4kaWX2/UpJN5Y7LABlq/Q1+3h33ylJ7r7TzMbl/aKZLZO0rML7AVCSmr9B5+5tktokyczid1QA1EylU289ZjZBkrLLXeUNCUAtVFr2lyXdmX1/p6R4/gZAwxU+jTezZyVdK2msmXVJ+o2kByU9Z2ZLJX0i6dZaDrLZFa31PXHixKpuv2jONpqvfvrpp8Ntd+zYEeZFa6Rfc801YT5z5syKb7vI4cOHw7yzszM3KzpO//333w/zr776KsybUWHZ3X1xTnRdyWMBUEN8XBZIBGUHEkHZgURQdiARlB1IBIe4liA6lbMkHTt2rKrbHzIk/mcaNy7308q67rp40mTbtm1hPnXq1DBfunRpmBcdpho5cOBAmH/88cdhHh2+e//994fbfvvtt2F+MmLPDiSCsgOJoOxAIig7kAjKDiSCsgOJoOxAIqzodLyl3tmP9Ew1RUsPL1++PMwXLlwY5mZ2wmOql6KxRf+/olM9S9KGDRvC/PHHHw/z6DDWvXv3htvWsxdlc/d+/1HYswOJoOxAIig7kAjKDiSCsgOJoOxAIig7kAiOZy9Bd3d3mH/yySdhvn///jAfNWrUCY/pZLBmzZowf/jhh8O8aFnlaB7/ZJ5HrxR7diARlB1IBGUHEkHZgURQdiARlB1IBGUHEsE8ewl6enrC/LHHHgvzouO6lyxZEuajR48O81oqOp79lVdeyc0effTRcNu33norzA8ePBjm+K7CPbuZPWlmu8xsU5/r7jOzT82sI/taUNthAqjWQJ7G/07SDf1c/4i7T8u+/lzusACUrbDs7r5a0ud1GAuAGqrmDbq7zWxD9jQ/90WjmS0zs/Vmtr6K+wJQpUrL/qikCyRNk7RT0m/zftHd29y91d1bK7wvACWoqOzu3uPuR939mKTHJcWnVwXQcBWV3cwm9Pnxp5I25f0ugOZQOM9uZs9KulbSWDPrkvQbSdea2TRJLqlT0s9rN8TmN2LEiDAvOq98UX7qqaeGeSOPzX7nnXfC/LnnnsvN1q5dG2779ddfVzQm9K+w7O6+uJ+rn6jBWADUEB+XBRJB2YFEUHYgEZQdSARlBxLBIa4lmDp1apgvWBAfFDh9+vQwHzZs2AmPqV5GjhwZ5seOHcvNmFqrL/bsQCIoO5AIyg4kgrIDiaDsQCIoO5AIyg4kgnn2AWppacnNFi5cGG57xRVXhPnw4cPDvOiUyfv27av4tosOzy06VfQFF1wQ5ldffXVutm7dunDb7du3hzlODHt2IBGUHUgEZQcSQdmBRFB2IBGUHUgEZQcSwTz7AM2cOTM3mzt3brjtueeeG+ZHjhwJ887OzjBfs2ZNbnb22WeH286fPz/Mhw4dWlV+ySWX5GZTpkwJt2WevVzs2YFEUHYgEZQdSARlBxJB2YFEUHYgEZQdSATz7AMUHbc9evTocNtBg+K/qQcOHAjzbdu2hflTTz0V5pHZs2eH+ahRo8K86Hj36Jz3RUtRo1yFe3Yzm2RmfzGzLWa22cx+mV0/xsxWmdlH2WX8Px5AQw3kafwRSb9294slXSPpF2Z2iaR7Jb3u7pMlvZ79DKBJFZbd3Xe6+3vZ919K2iJpoqRFklZmv7ZS0o01GiOAEpzQa3YzO0/SdEnrJI13951S7x8EMxuXs80yScuqHCeAKg247GZ2uqQ/SvqVu+8vemPmOHdvk9SW3YZXMkgA1RvQ1JuZDVVv0Z929z9lV/eY2YQsnyBpV22GCKAMhXt2692FPyFpi7uv6BO9LOlOSQ9mly/VZIRNoqOjIzfbs2dPuG3RIa5Fp3tubW0N8zvuuCM3W7FiRW4mST09PWFedKrpU045JczRPAbyNH6WpDskbTSzjuy65eot+XNmtlTSJ5JurckIAZSisOzu/ldJeS/Qryt3OABqhY/LAomg7EAiKDuQCMoOJIKyA4ngENcB2rBhQ25WdAjqRRddFOZFc9lFh9BGyyIXLRfd3t4e5uPHjw9z5tlPHuzZgURQdiARlB1IBGUHEkHZgURQdiARlB1IBPPsA7RrV/65OV577bVw25aWljCfNm1amJ922mlhPnny5NzsgQceCLc9/fTTw/yMM84Ic5w82LMDiaDsQCIoO5AIyg4kgrIDiaDsQCIoO5AI5tkH6PDhw7nZq6++Gm67Y8eOML/55pvD/JZbbgnzMWPG5GZF56xHOtizA4mg7EAiKDuQCMoOJIKyA4mg7EAiKDuQiIGszz5J0u8lnS3pmKQ2d/9fM7tP0l2Sdme/utzd/1yrgTaz7u7uMN+7d2+YDxoU/80dO3ZsmM+ZMyc3O+uss8Jtay06D8Du3btzM5RvIB+qOSLp1+7+npmdIandzFZl2SPu/nDthgegLANZn32npJ3Z91+a2RZJE2s9MADlOqHX7GZ2nqTpktZlV91tZhvM7Ekz63eNIjNbZmbrzWx9dUMFUI0Bl93MTpf0R0m/cvf9kh6VdIGkaerd8/+2v+3cvc3dW929tfrhAqjUgMpuZkPVW/Sn3f1PkuTuPe5+1N2PSXpc0ozaDRNAtQrLbmYm6QlJW9x9RZ/rJ/T5tZ9K2lT+8ACUxdw9/gWz2ZLWSNqo3qk3SVouabF6n8K7pE5JP8/ezItuK76zRI0bNy7Mp0+fHuatrfmvkIqm7Wpt7dq1udnq1avDbT/77LOyh5MEd7f+rh/Iu/F/ldTfxknOqQMnKz5BBySCsgOJoOxAIig7kAjKDiSCsgOJKJxnL/XOmGcHai5vnp09O5AIyg4kgrIDiaDsQCIoO5AIyg4kgrIDiaj3ks17JH3c5+ex2XXNqFnH1qzjkhhbpcoc27/kBXX9UM0P7txsfbOem65Zx9as45IYW6XqNTaexgOJoOxAIhpd9rYG33+kWcfWrOOSGFul6jK2hr5mB1A/jd6zA6gTyg4koiFlN7MbzOzvZrbVzO5txBjymFmnmW00s45Gr0+XraG3y8w29blujJmtMrOPsst+19hr0NjuM7NPs8euw8wWNGhsk8zsL2a2xcw2m9kvs+sb+tgF46rL41b31+xmNljSPyTNldQl6V1Ji939b3UdSA4z65TU6u4N/wCGmf2rpK8k/d7dp2bX/Y+kz939wewP5Wh3/68mGdt9kr5q9DLe2WpFE/ouMy7pRkn/qQY+dsG4/kN1eNwasWefIWmru29390OS/iBpUQPG0fTcfbWkz7939SJJK7PvV6r3P0vd5YytKbj7Tnd/L/v+S0nHlxlv6GMXjKsuGlH2iZJ29Pm5S8213rtLes3M2s1sWaMH04/xx5fZyi7jtaPqr3AZ73r63jLjTfPYVbL8ebUaUfb+zo/VTPN/s9z9Ckn/LukX2dNVDMyAlvGul36WGW8KlS5/Xq1GlL1L0qQ+P7dI6m7AOPrl7t3Z5S5JL6j5lqLuOb6Cbna5q8Hj+admWsa7v2XG1QSPXSOXP29E2d+VNNnMfmJmp0j6maSXGzCOHzCzEdkbJzKzEZLmqfmWon5Z0p3Z93dKeqmBY/mOZlnGO2+ZcTX4sWv48ufuXvcvSQvU+478Nkn/3Ygx5IzrfEkfZF+bGz02Sc+q92ndYfU+I1oq6SxJr0v6KLsc00Rje0q9S3tvUG+xJjRobLPV+9Jwg6SO7GtBox+7YFx1edz4uCyQCD5BBySCsgOJoOxAIig7kAjKDiSCsgOJoOxAIv4fac29vQdgeSEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "# plotting 2 images from MNIST datset (2 to make sure I didn't make a mistake in transforming the dataset)\n",
    "\n",
    "batch_MNIST_0 = train_MNIST_transformed[0]\n",
    "images0 = batch_MNIST_0[0]\n",
    "image0 = images0[0]\n",
    "image1 = images0[1]\n",
    "\n",
    "plt.imshow(image0.view(28,28), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(image1.view(28,28), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "print(len(train_MNIST_transformed)*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the USPS data according to how it is done in the paper. First interpolating so that images are 32x32 and than performing 'random' 28x28 crop\n",
    "\n",
    "train_USPS_transformed = [] # initializing the entire (batched) dataset as an empty list\n",
    "\n",
    "for batch_USPS in trainset_USPS:\n",
    "        \n",
    "    images = batch_USPS[0] # taking the images from the dataset batch. this a torch.tensor of shape (32, 1, 28, 28)\n",
    "    labels = batch_USPS[1] # taking the labels from the dataset batch. \n",
    "    \n",
    "    images_transformed = torch.zeros(size=torch.Size([32, 1, 28, 28])) # initializing the transformed images with the same shape as images (32, 1, 28, 28)\n",
    "        \n",
    "    for i in range(0, len(images)):\n",
    "        \n",
    "        image = images[i] \n",
    "        \n",
    "        image_transformed = p(image) # transforming the image with predefined transformation \"p\"\n",
    "        images_transformed[i] = image_transformed # replacing zero tensor (1, 28, 28) in images_transformed with the transformed image\n",
    "            \n",
    "    batch_USPS_transformed = [images_transformed, labels] # transformed batch is simply a list of batch of images in [0] and batch of labels in [1]\n",
    "    \n",
    "    train_USPS_transformed.append(batch_USPS_transformed) # appending to the empty dataset list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7296\n"
     ]
    }
   ],
   "source": [
    "# plotting 2 images from USPS datset (2 to make sure I didn't make a mistake in transforming the dataset)\n",
    "\n",
    "batch_USPS_0 = train_USPS_transformed[0]\n",
    "\n",
    "images0 = batch_USPS_0[0]\n",
    "image0 = images0[0]\n",
    "image1 = images0[1]\n",
    "\n",
    "plt.imshow(image0.view(28,28), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(image1.view(28,28), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "print(len(train_USPS_transformed)*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from model import fNet, gNet, Discriminator, hSim, SimNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights_disc(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.uniform_(m.weight)\n",
    "#         m.bias.data.fill_(0.01) # do we need something like this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take prototypes from MNIST (in the future they have to be chosen randomly --> shuffle?)\n",
    "prototype_images = [0] * 10\n",
    "\n",
    "for source_data in train_MNIST_transformed:\n",
    "    X_source, y_source = source_data\n",
    "    \n",
    "    for j in range(0, len(y_source)):\n",
    "        \n",
    "        if torch.sum(torch.Tensor(prototype_images[int(y_source[j])])) == 0:\n",
    "            prototype_images[int(y_source[j])] = X_source[j].view(1, 1, 28, 28) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for prototype_image in prototype_images:\n",
    "#     print(prototype_image.shape)\n",
    "#     plt.imshow(prototype_image.view(28,28), cmap=\"gray\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_class: tensor(224.5517, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(inf, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<AddBackward0>)\n",
      "loss_disc: tensor(nan, grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "gamma_reg = 0.01\n",
    "lambda_loss= 0.5\n",
    "\n",
    "simnet = SimNet()\n",
    "gnet = gNet()\n",
    "simnet.apply(init_weights_disc)\n",
    "\n",
    "optimizerSimNet = torch.optim.SGD(simnet.parameters(), lr=0.001, momentum=0.99, weight_decay=0.00001)\n",
    "\n",
    "for epoch in range(3): # 3 full passes over the data\n",
    "    \n",
    "    num_batches = len(train_USPS_transformed)\n",
    "\n",
    "    for i in range(0, num_batches):\n",
    "        \n",
    "        MNIST_batch = train_MNIST_transformed[i]\n",
    "        USPS_batch = train_USPS_transformed[i]\n",
    "        \n",
    "        X_MNIST, y_MNIST = MNIST_batch\n",
    "        X_USPS, y_USPS = USPS_batch\n",
    "        \n",
    "        simnet.zero_grad()\n",
    "        \n",
    "        prototypes = gnet.calcproto(prototype_images)\n",
    "        \n",
    "        Regularizer = torch.norm(torch.matmul(prototypes.t(), prototypes) - torch.eye(128))\n",
    "        Regularizer = Regularizer*Regularizer\n",
    "        \n",
    "        [source_class_output, source_domain_output] = simnet(X_MNIST, prototype_images)\n",
    "        [target_class_output, target_domain_output] = simnet(X_USPS, prototype_images)\n",
    "        \n",
    "        loss_class = F.nll_loss(source_class_output, y_MNIST) + gamma_reg * Regularizer\n",
    "        loss_disc = - torch.sum(torch.log(source_domain_output)) - torch.sum(torch.log(1 - source_domain_output))\n",
    "\n",
    "        total_loss = loss_class - lambda_loss * loss_disc        \n",
    "        total_loss.backward()\n",
    "        \n",
    "        optimizerSimNet.step()\n",
    "        \n",
    "        print(\"loss_class: \" + str(loss_class))\n",
    "        print(\"loss_disc: \" + str(loss_disc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026],\n",
      "        [-2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026, -2.3026,\n",
      "         -2.3026, -2.3026]], grad_fn=<CopySlices>)\n",
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
      "        4, 0, 7, 4, 0, 1, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "for test_batch in testset_MNIST:\n",
    "    \n",
    "    X, y = test_batch\n",
    "    [class_output, domain_output] = simnet(X, prototype_images)\n",
    "    \n",
    "#     print(domain_output)\n",
    "    print(class_output)\n",
    "    print(y)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
