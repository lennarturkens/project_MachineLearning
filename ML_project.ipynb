{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_revgrad import RevGrad\n",
    "\n",
    "train_MNIST = datasets.MNIST('', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test_MNIST = datasets.MNIST('', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "train_USPS = datasets.USPS('USPS', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test_USPS = datasets.USPS('USPS', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "trainset_MNIST = torch.utils.data.DataLoader(train_MNIST, batch_size=32, shuffle=True)\n",
    "testset_MNIST = torch.utils.data.DataLoader(test_MNIST, batch_size=32, shuffle=False)\n",
    "\n",
    "trainset_USPS = torch.utils.data.DataLoader(train_USPS, batch_size=32, shuffle=True)\n",
    "testset_USPS = torch.utils.data.DataLoader(test_USPS, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the transformation\n",
    "\n",
    "p = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.RandomCrop((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that transforms the data according to how it is done in the paper. First interpolating so that images are 32x32 and than performing 'random' 28x28 crop\n",
    "\n",
    "def transformdata(data):\n",
    "    data_transformed = [] # initializing the entire (batched) dataset as an empty list\n",
    "    \n",
    "    for batch in data:\n",
    "        \n",
    "        images = batch[0]\n",
    "        labels = batch[1]\n",
    "        \n",
    "        images_transformed = torch.zeros(size=torch.Size([32, 1, 28, 28])) # initializing the transformed images with the same shape as images (32, 1, 28, 28)\n",
    "\n",
    "        for i in range(0, len(images)):\n",
    "            \n",
    "            image = images[i]\n",
    "            \n",
    "            image_transformed = p(image) # transforming the image with predefined transformation \"p\"\n",
    "            images_transformed[i] = image_transformed # replacing zero tensor (1, 28, 28) in images_transformed with the transformed image\n",
    "            \n",
    "        batch_transformed = [images_transformed, labels] # transformed batch is simply a list of batch of images in [0] and batch of labels in [1]\n",
    "    \n",
    "        data_transformed.append(batch_transformed) # appending to the empty dataset list\n",
    "        \n",
    "    return data_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming data\n",
    "\n",
    "train_MNIST_transformed = transformdata(trainset_MNIST)\n",
    "test_MNIST_transformed = transformdata(testset_MNIST)\n",
    "train_USPS_transformed = transformdata(trainset_USPS)\n",
    "test_USPS_transformed = transformdata(testset_USPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting 2 images from MNIST datset (2 to make sure I didn't make a mistake in transforming the dataset)\n",
    "\n",
    "batch_MNIST_0 = train_MNIST_transformed[0]\n",
    "images0 = batch_MNIST_0[0]\n",
    "\n",
    "plt.figure(figsize=(5,5)) # specifying the overall grid size\n",
    "\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1)    # the number of images in the grid is 5*5 (25)\n",
    "    plt.imshow(images0[i].view(28,28), cmap=\"gray\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plotting 2 images from USPS datset (2 to make sure I didn't make a mistake in transforming the dataset)\n",
    "\n",
    "batch_USPS_0 = train_USPS_transformed[0]\n",
    "\n",
    "images0 = batch_USPS_0[0]\n",
    "\n",
    "plt.figure(figsize=(5,5)) # specifying the overall grid size\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1)    # the number of images in the grid is 5*5 (25)\n",
    "    plt.imshow(images0[i].view(28,28), cmap=\"gray\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7296\n"
     ]
    }
   ],
   "source": [
    "# plotting 2 images from USPS datset (2 to make sure I didn't make a mistake in transforming the dataset)\n",
    "\n",
    "batch_USPS_0 = train_USPS_transformed[0]\n",
    "\n",
    "images0 = batch_USPS_0[0]\n",
    "image0 = images0[0]\n",
    "image1 = images0[1]\n",
    "\n",
    "plt.imshow(image0.view(28,28), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(image1.view(28,28), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "print(len(train_USPS_transformed)*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from model import fNet, gNet, Discriminator, hSim, SimNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights_disc(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.uniform_(m.weight)\n",
    "        nn.init.uniform_(m.bias)\n",
    "#         m.bias.data.uniform_()\n",
    "#         m.bias.data.fill_(0.01) # do we need something like this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take prototypes from MNIST (in the future they have to be chosen randomly --> shuffle?)\n",
    "prototype_images = [0] * 10\n",
    "\n",
    "for source_data in train_MNIST_transformed:\n",
    "    X_source, y_source = source_data\n",
    "    \n",
    "    for j in range(0, len(y_source)):\n",
    "        \n",
    "        if torch.sum(torch.Tensor(prototype_images[int(y_source[j])])) == 0:\n",
    "            prototype_images[int(y_source[j])] = X_source[j].view(1, 1, 28, 28) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(fNet, self).__init__()\n",
    "        \n",
    "        self.restored = False\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, 5)   # 1st conv layer INPUT [1 x 28 x 28] OUTPUT [64 x 12 x 12]\n",
    "        self.conv2 = nn.Conv2d(64, 64, 5)  # 2nd conv layer INPUT [64 x 12 x 12] OUTPUT [64 x 4 x 4]\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5) # 3rd conv layer INPUT [64 x 4 x 4] OUTPUT [128 x 1 x 1]\n",
    "        self.bn1 = nn.BatchNorm2d(64, eps=1e-05) # batch normalisation\n",
    "        self.pool = nn.MaxPool2d(2, 2, padding=1)\n",
    "         \n",
    "    def forward(self, x):\n",
    "        output = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        output = self.pool(F.relu(self.bn1(self.conv2(output))))\n",
    "        output = F.relu(self.conv3(output))\n",
    "        output = output.view(-1, 128 * 1 * 1)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "class gNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(gNet, self).__init__()\n",
    "        \n",
    "        self.restored = False\n",
    "                \n",
    "        self.conv1 = nn.Conv2d(1, 64, 5)      # 1st conv layer INPUT [1 x 28 x 28]  OUTPUT [64 x 12 x 12]\n",
    "        self.conv2 = nn.Conv2d(64, 64, 5)     # 2nd conv layer INPUT [64 x 12 x 12] OUTPUT [64 x 4 x 4]\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)    # 3rd conv layer INPUT [64 x 4 x 4]   OUTPUT [128 x 1 x 1]\n",
    "        self.bn1 = nn.BatchNorm2d(64, eps=1e-05) # batch normalisation\n",
    "        self.pool = nn.MaxPool2d(2, 2, padding=1)\n",
    "        \n",
    "         \n",
    "    def forward(self, x):\n",
    "        output = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        output = self.pool(F.relu(self.bn1(self.conv2(output))))\n",
    "        output = F.relu(self.conv3(output))\n",
    "        output = output.view(-1, 128 * 1 *1)\n",
    "        return output\n",
    "\n",
    "\n",
    "    def calcproto(self, class_list):\n",
    "        \n",
    "        g_output = []\n",
    "        \n",
    "        for class_image in class_list:\n",
    "            g_output_class = self.forward(class_image)\n",
    "            g_output.append(g_output_class)\n",
    "        \n",
    "        num_classes = len(g_output) # number of classes (10 in Digits experiment)\n",
    "        num_features = g_output_class.shape[1] # number of features (128 in Digits experiment)\n",
    "            \n",
    "        prototypes = torch.Tensor(size=torch.Size([num_features, num_classes]))\n",
    "        \n",
    "        class_count = 0\n",
    "        \n",
    "        for g_output_class in g_output:\n",
    "            \n",
    "            prototype = torch.mean(g_output_class, dim=0) # calculating the prototype for each class while testing\n",
    "            prototypes[:,class_count] = prototype\n",
    "                        \n",
    "            class_count += 1\n",
    "                    \n",
    "        return prototypes\n",
    "    \n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.restored = False\n",
    "\n",
    "        \n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(128, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 2),\n",
    "            RevGrad()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.layer(x)\n",
    "        \n",
    "        output = output/torch.max(output)\n",
    "\n",
    "        output = F.softmax(output, dim=1) \n",
    "#         print(output)\n",
    "        \n",
    "        \n",
    "        return output[:, 0]\n",
    "    \n",
    "    \n",
    "class hSim(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "\n",
    "        self.restored = False\n",
    "        \n",
    "        \n",
    "        self.U = nn.Parameter(torch.rand(size=(512, 128), requires_grad=True))\n",
    "        self.V = nn.Parameter(torch.rand(size=(512, 128), requires_grad=True))\n",
    "        \n",
    "    def forward(self, f_batch, mu_c):\n",
    "        \n",
    "        h_batch = torch.zeros(size=[32, 10]) # batchsize = 32 maybe 'automate' this size so we don't get in trouble later      when we may change the batch size (same goes for number of classes (10))\n",
    "        \n",
    "        \n",
    "        for i in range(0, len(f_batch)):\n",
    "        \n",
    "            f_i = f_batch[i]\n",
    "            fac1 = torch.matmul(self.U, f_i)\n",
    "            fac1_t = fac1.t()\n",
    "                        \n",
    "            fac2 = torch.matmul(self.V, mu_c)\n",
    "    \n",
    "            h = torch.matmul(fac1_t, fac2)\n",
    "#             h = F.softmax(h/torch.max(h), dim=0)\n",
    "            \n",
    "            \n",
    "            h_batch[i] = h\n",
    "            \n",
    "        \n",
    "        return h_batch   \n",
    "    \n",
    "    \n",
    "class SimNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.restored = False\n",
    "    \n",
    "        self.fnet = fNet()\n",
    "        self.gnet = gNet()\n",
    "        self.disc = Discriminator()\n",
    "        self.hsim = hSim()\n",
    "        \n",
    "        \n",
    "    def forward(self, f_input, g_input):\n",
    "        # f_input is batch of images\n",
    "        # g_input should be a list (in the future maybe change to tensor?) of one (while training --> randomly chosen) or more (while testing --> every from test_batch) image(s) of every class\n",
    "        \n",
    "        f_output = self.fnet(f_input)\n",
    "        prototypes = self.gnet.calcproto(g_input)\n",
    "                        \n",
    "        Regularizer = torch.norm(torch.matmul(prototypes, prototypes.t()) - torch.eye(128))\n",
    "        Regularizer = Regularizer*Regularizer\n",
    "                \n",
    "        class_output = self.hsim(f_output, prototypes)\n",
    "        disc_output = self.disc(f_output)\n",
    "        \n",
    "        return [class_output, disc_output, Regularizer] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13428.2197, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7037, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3623, grad_fn=<SubBackward0>)\n",
      "tensor(13580.4102, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6626, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3540, grad_fn=<SubBackward0>)\n",
      "tensor(14042.3174, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7202, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3625, grad_fn=<SubBackward0>)\n",
      "tensor(14532.9473, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7794, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3589, grad_fn=<SubBackward0>)\n",
      "tensor(15018.6602, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6586, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3606, grad_fn=<SubBackward0>)\n",
      "tensor(15457.3652, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7364, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3570, grad_fn=<SubBackward0>)\n",
      "tensor(16183.5020, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.8470, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3573, grad_fn=<SubBackward0>)\n",
      "tensor(17408.1602, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7440, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3557, grad_fn=<SubBackward0>)\n",
      "tensor(18969.6602, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7593, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3585, grad_fn=<SubBackward0>)\n",
      "tensor(21231.4727, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7648, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3620, grad_fn=<SubBackward0>)\n",
      "tensor(23985.8027, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.4965, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3562, grad_fn=<SubBackward0>)\n",
      "tensor(26587.6328, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6367, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3619, grad_fn=<SubBackward0>)\n",
      "tensor(29357.4629, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7058, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3602, grad_fn=<SubBackward0>)\n",
      "tensor(32283.7148, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.5522, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3573, grad_fn=<SubBackward0>)\n",
      "tensor(35445.7891, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.5046, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3650, grad_fn=<SubBackward0>)\n",
      "tensor(38376.8086, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.8268, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3625, grad_fn=<SubBackward0>)\n",
      "tensor(42344.1914, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7985, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3600, grad_fn=<SubBackward0>)\n",
      "tensor(47338.6992, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7882, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3546, grad_fn=<SubBackward0>)\n",
      "tensor(53378.2031, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7021, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3618, grad_fn=<SubBackward0>)\n",
      "tensor(60400.2695, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7899, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3394, grad_fn=<SubBackward0>)\n",
      "tensor(68724.1875, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.5290, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3484, grad_fn=<SubBackward0>)\n",
      "tensor(77157.3047, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7446, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3542, grad_fn=<SubBackward0>)\n",
      "tensor(86514.4531, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.5187, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3509, grad_fn=<SubBackward0>)\n",
      "tensor(95950.8516, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6725, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3474, grad_fn=<SubBackward0>)\n",
      "tensor(106371.0078, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.8368, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3581, grad_fn=<SubBackward0>)\n",
      "tensor(118503.3359, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6795, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3487, grad_fn=<SubBackward0>)\n",
      "tensor(131370.8750, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6627, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3651, grad_fn=<SubBackward0>)\n",
      "tensor(145224.5312, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.9288, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3435, grad_fn=<SubBackward0>)\n",
      "tensor(162017.6719, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.5841, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3466, grad_fn=<SubBackward0>)\n",
      "tensor(179320.6719, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.4591, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3441, grad_fn=<SubBackward0>)\n",
      "tensor(195625.0938, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.5100, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3547, grad_fn=<SubBackward0>)\n",
      "tensor(211022.3281, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7664, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3691, grad_fn=<SubBackward0>)\n",
      "tensor(227660.2969, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6809, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3422, grad_fn=<SubBackward0>)\n",
      "tensor(244539.7344, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7346, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3385, grad_fn=<SubBackward0>)\n",
      "tensor(262643.6250, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7915, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3253, grad_fn=<SubBackward0>)\n",
      "tensor(282544.6250, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.9234, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3289, grad_fn=<SubBackward0>)\n",
      "tensor(305384.4062, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.8501, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3237, grad_fn=<SubBackward0>)\n",
      "tensor(331140.1250, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7501, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.2922, grad_fn=<SubBackward0>)\n",
      "tensor(358603.5312, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7134, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3130, grad_fn=<SubBackward0>)\n",
      "tensor(386946.9375, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7377, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3115, grad_fn=<SubBackward0>)\n",
      "tensor(416812.6562, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6124, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.2723, grad_fn=<SubBackward0>)\n",
      "tensor(446373.3125, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.4225, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3160, grad_fn=<SubBackward0>)\n",
      "tensor(472998.6250, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7827, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3239, grad_fn=<SubBackward0>)\n",
      "tensor(501820.4062, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7694, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3149, grad_fn=<SubBackward0>)\n",
      "tensor(532752.4375, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.8253, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.2705, grad_fn=<SubBackward0>)\n",
      "tensor(566933.0625, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6997, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.2877, grad_fn=<SubBackward0>)\n",
      "tensor(603472.8125, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.8734, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3390, grad_fn=<SubBackward0>)\n",
      "tensor(645343.0625, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.4897, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.2245, grad_fn=<SubBackward0>)\n",
      "tensor(686254.5625, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6093, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.2810, grad_fn=<SubBackward0>)\n",
      "tensor(726328.5000, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6979, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3368, grad_fn=<SubBackward0>)\n",
      "tensor(769123.8750, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7104, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.1816, grad_fn=<SubBackward0>)\n",
      "tensor(814444., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6578, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.1870, grad_fn=<SubBackward0>)\n",
      "tensor(860392.5625, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6722, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.1663, grad_fn=<SubBackward0>)\n",
      "tensor(907650.2500, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6435, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.2820, grad_fn=<SubBackward0>)\n",
      "tensor(955363.0625, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6694, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.1863, grad_fn=<SubBackward0>)\n",
      "tensor(1004048.6250, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6679, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.0998, grad_fn=<SubBackward0>)\n",
      "tensor(1055026.3750, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.3913, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.1762, grad_fn=<SubBackward0>)\n",
      "tensor(1101484.6250, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6178, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.3263, grad_fn=<SubBackward0>)\n",
      "tensor(1148852.1250, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7472, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.1206, grad_fn=<SubBackward0>)\n",
      "tensor(1198588., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.5538, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.9663, grad_fn=<SubBackward0>)\n",
      "tensor(1246377.6250, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6185, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.1731, grad_fn=<SubBackward0>)\n",
      "tensor(1293966.5000, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6084, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.0342, grad_fn=<SubBackward0>)\n",
      "tensor(1341734.5000, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7649, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.9517, grad_fn=<SubBackward0>)\n",
      "tensor(1392826.3750, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.8718, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.0231, grad_fn=<SubBackward0>)\n",
      "tensor(1450270.3750, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6556, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.8288, grad_fn=<SubBackward0>)\n",
      "tensor(1509799.8750, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6178, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.9967, grad_fn=<SubBackward0>)\n",
      "tensor(1569697., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.8706, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.9855, grad_fn=<SubBackward0>)\n",
      "tensor(1636186.6250, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.4440, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.9409, grad_fn=<SubBackward0>)\n",
      "tensor(1697894., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.5773, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.9574, grad_fn=<SubBackward0>)\n",
      "tensor(1757415., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7699, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.1517, grad_fn=<SubBackward0>)\n",
      "tensor(1819859.6250, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.5680, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.1546, grad_fn=<SubBackward0>)\n",
      "tensor(1880780.2500, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.8008, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.8284, grad_fn=<SubBackward0>)\n",
      "tensor(1945474.3750, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.5629, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.5889, grad_fn=<SubBackward0>)\n",
      "tensor(2006241.8750, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6394, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.5683, grad_fn=<SubBackward0>)\n",
      "tensor(2067039.1250, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.4578, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.0449, grad_fn=<SubBackward0>)\n",
      "tensor(2123272.2500, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7893, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.4893, grad_fn=<SubBackward0>)\n",
      "tensor(2184465., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7066, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.8875, grad_fn=<SubBackward0>)\n",
      "tensor(2247020.5000, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.8729, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.6919, grad_fn=<SubBackward0>)\n",
      "tensor(2316713., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6472, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.4012, grad_fn=<SubBackward0>)\n",
      "tensor(2388655.5000, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.5857, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(44.1573, grad_fn=<SubBackward0>)\n",
      "tensor(2458399., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.5366, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.4814, grad_fn=<SubBackward0>)\n",
      "tensor(2525910.2500, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7714, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.4782, grad_fn=<SubBackward0>)\n",
      "tensor(2597098.7500, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.4540, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.3815, grad_fn=<SubBackward0>)\n",
      "tensor(2660458., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.8065, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.4266, grad_fn=<SubBackward0>)\n",
      "tensor(2730787.2500, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6704, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.4179, grad_fn=<SubBackward0>)\n",
      "tensor(2801609., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.3845, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.3205, grad_fn=<SubBackward0>)\n",
      "tensor(2862014., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7892, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.2034, grad_fn=<SubBackward0>)\n",
      "tensor(2927021.7500, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.8830, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.3982, grad_fn=<SubBackward0>)\n",
      "tensor(3000658.2500, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.8474, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.4150, grad_fn=<SubBackward0>)\n",
      "tensor(3081698., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7245, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.3798, grad_fn=<SubBackward0>)\n",
      "tensor(3166314., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7741, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.0616, grad_fn=<SubBackward0>)\n",
      "tensor(3255976.2500, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6717, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(42.9946, grad_fn=<SubBackward0>)\n",
      "tensor(3347793.7500, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6769, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(42.9189, grad_fn=<SubBackward0>)\n",
      "tensor(3441369.7500, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7937, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(42.9867, grad_fn=<SubBackward0>)\n",
      "tensor(3542609., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7943, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(42.9089, grad_fn=<SubBackward0>)\n",
      "tensor(3648245.5000, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.5583, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.1092, grad_fn=<SubBackward0>)\n",
      "tensor(3751007.7500, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.5364, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.2039, grad_fn=<SubBackward0>)\n",
      "tensor(3849715., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.9727, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(42.6658, grad_fn=<SubBackward0>)\n",
      "tensor(3960973.5000, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.4221, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(42.7584, grad_fn=<SubBackward0>)\n",
      "tensor(4062843., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.5080, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.2674, grad_fn=<SubBackward0>)\n",
      "tensor(4158339., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7380, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(42.8120, grad_fn=<SubBackward0>)\n",
      "tensor(4255985., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6401, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(42.2260, grad_fn=<SubBackward0>)\n",
      "tensor(4352385., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.5901, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(42.5113, grad_fn=<SubBackward0>)\n",
      "tensor(4442707., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.7684, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(42.1742, grad_fn=<SubBackward0>)\n",
      "tensor(4540926., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6389, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(42.4212, grad_fn=<SubBackward0>)\n",
      "tensor(4638527.5000, grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.8535, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(42.6943, grad_fn=<SubBackward0>)\n",
      "tensor(4745209., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(73.6485, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(43.3653, grad_fn=<SubBackward0>)\n",
      "tensor(4851698., grad_fn=<MulBackward0>)\n",
      "loss_class: tensor(nan, grad_fn=<SubBackward0>)\n",
      "loss_disc: tensor(42.3395, grad_fn=<SubBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "select(): index 0 out of range for tensor of size [0, 1] at dimension 0\nException raised from select at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:889 (most recent call first):\n00007FFB9BF06AD600007FFB9BF06A70 c10.dll!c10::Error::Error [<unknown file> @ <unknown line number>]\n00007FFB9BEE387C00007FFB9BEE3800 c10.dll!c10::IndexError::IndexError [<unknown file> @ <unknown line number>]\n00007FFB45D55ED100007FFB45D55A10 torch_cpu.dll!at::native::select [<unknown file> @ <unknown line number>]\n00007FFB4602A9FE00007FFB45FAB700 torch_cpu.dll!at::zeros_out [<unknown file> @ <unknown line number>]\n00007FFB45AF844A00007FFB45AED8A0 torch_cpu.dll!torch::nn::functional::BatchNormFuncOptions::~BatchNormFuncOptions [<unknown file> @ <unknown line number>]\n00007FFB45EF843A00007FFB45E73840 torch_cpu.dll!at::native::mkldnn_sigmoid_ [<unknown file> @ <unknown line number>]\n00007FFB45F9751100007FFB45F97450 torch_cpu.dll!at::select [<unknown file> @ <unknown line number>]\n00007FFB4714FDA500007FFB47137970 torch_cpu.dll!torch::autograd::GraphRoot::apply [<unknown file> @ <unknown line number>]\n00007FFB45AF844A00007FFB45AED8A0 torch_cpu.dll!torch::nn::functional::BatchNormFuncOptions::~BatchNormFuncOptions [<unknown file> @ <unknown line number>]\n00007FFB45EF843A00007FFB45E73840 torch_cpu.dll!at::native::mkldnn_sigmoid_ [<unknown file> @ <unknown line number>]\n00007FFB4606026100007FFB460601A0 torch_cpu.dll!at::Tensor::select [<unknown file> @ <unknown line number>]\n00007FFB470DB3F900007FFB470DB050 torch_cpu.dll!torch::autograd::SavedVariable::reset_grad_function [<unknown file> @ <unknown line number>]\n00007FFB470A0EC400007FFB470A0D90 torch_cpu.dll!torch::autograd::generated::MaxBackward1::apply [<unknown file> @ <unknown line number>]\n00007FFB4707D96700007FFB4707D760 torch_cpu.dll!torch::autograd::Node::operator() [<unknown file> @ <unknown line number>]\n00007FFB475559F900007FFB475554A0 torch_cpu.dll!torch::autograd::Engine::add_thread_pool_task [<unknown file> @ <unknown line number>]\n00007FFB475565A500007FFB47556290 torch_cpu.dll!torch::autograd::Engine::evaluate_function [<unknown file> @ <unknown line number>]\n00007FFB4755B52C00007FFB4755B220 torch_cpu.dll!torch::autograd::Engine::thread_main [<unknown file> @ <unknown line number>]\n00007FFB47557BFF00007FFB47557A10 torch_cpu.dll!torch::autograd::Engine::execute_with_graph_task [<unknown file> @ <unknown line number>]\n00007FFB6859307800007FFB6856C550 torch_python.dll!THPShortStorage_New [<unknown file> @ <unknown line number>]\n00007FFB4755793D00007FFB47557600 torch_cpu.dll!torch::autograd::Engine::execute [<unknown file> @ <unknown line number>]\n00007FFB68592F4400007FFB6856C550 torch_python.dll!THPShortStorage_New [<unknown file> @ <unknown line number>]\n00007FFB6859190000007FFB6856C550 torch_python.dll!THPShortStorage_New [<unknown file> @ <unknown line number>]\n00007FFB6CFDE9F500007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFDF2BF00007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFE04E900007FFB6CFDF4F0 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFB6CFC8EB600007FFB6CFC8D10 python37.dll!PyEval_EvalCodeWithName [<unknown file> @ <unknown line number>]\n00007FFB6CFDF38700007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFDFDA200007FFB6CFDF4F0 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFB6CFC8EB600007FFB6CFC8D10 python37.dll!PyEval_EvalCodeWithName [<unknown file> @ <unknown line number>]\n00007FFB6CFDF38700007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFDF8F300007FFB6CFDF4F0 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFB6CFC8EB600007FFB6CFC8D10 python37.dll!PyEval_EvalCodeWithName [<unknown file> @ <unknown line number>]\n00007FFB6CFA732F00007FFB6CFA718C python37.dll!PyErr_Clear [<unknown file> @ <unknown line number>]\n00007FFB6CFA720500007FFB6CFA718C python37.dll!PyErr_Clear [<unknown file> @ <unknown line number>]\n00007FFB6CFDE75000007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFDF2BF00007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFDF99F00007FFB6CFDF4F0 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFB6CFC517400007FFB6CFC4F2C python37.dll!PyObject_GetAttrId [<unknown file> @ <unknown line number>]\n00007FFB6D0258AC00007FFB6CFFE9B0 python37.dll!PyErr_NoMemory [<unknown file> @ <unknown line number>]\n00007FFB6CFC517400007FFB6CFC4F2C python37.dll!PyObject_GetAttrId [<unknown file> @ <unknown line number>]\n00007FFB6D0258AC00007FFB6CFFE9B0 python37.dll!PyErr_NoMemory [<unknown file> @ <unknown line number>]\n00007FFB6CFC517400007FFB6CFC4F2C python37.dll!PyObject_GetAttrId [<unknown file> @ <unknown line number>]\n00007FFB6CFDE77100007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFDF0FC00007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFDF8F300007FFB6CFDF4F0 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFB6CFDF25B00007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFDF99F00007FFB6CFDF4F0 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFB6CFDF25B00007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFDF8F300007FFB6CFDF4F0 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFB6CFC8EB600007FFB6CFC8D10 python37.dll!PyEval_EvalCodeWithName [<unknown file> @ <unknown line number>]\n00007FFB6CFC8B3A00007FFB6CFC8980 python37.dll!PyFunction_FastCallDict [<unknown file> @ <unknown line number>]\n00007FFB6CFC7AEA00007FFB6CFC7740 python37.dll!PyMethodDef_RawFastCallDict [<unknown file> @ <unknown line number>]\n00007FFB6CFEED1400007FFB6CFEEB60 python37.dll!PySlice_New [<unknown file> @ <unknown line number>]\n00007FFB6CFE066400007FFB6CFDF4F0 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFB6CFC8EB600007FFB6CFC8D10 python37.dll!PyEval_EvalCodeWithName [<unknown file> @ <unknown line number>]\n00007FFB6CFDF38700007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFE04E900007FFB6CFDF4F0 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFB6CFC517400007FFB6CFC4F2C python37.dll!PyObject_GetAttrId [<unknown file> @ <unknown line number>]\n00007FFB6D11F35600007FFB6D11BA64 python37.dll!PyAST_Optimize [<unknown file> @ <unknown line number>]\n00007FFB6CFDE75000007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFDF2BF00007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFDF99F00007FFB6CFDF4F0 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFB6CFC8EB600007FFB6CFC8D10 python37.dll!PyEval_EvalCodeWithName [<unknown file> @ <unknown line number>]\n00007FFB6CFDF38700007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-9baa2741eb45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_class\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlambda_loss\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mloss_disc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mtotal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0moptimizerSimNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachineLearning_OldPy\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachineLearning_OldPy\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: select(): index 0 out of range for tensor of size [0, 1] at dimension 0\nException raised from select at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:889 (most recent call first):\n00007FFB9BF06AD600007FFB9BF06A70 c10.dll!c10::Error::Error [<unknown file> @ <unknown line number>]\n00007FFB9BEE387C00007FFB9BEE3800 c10.dll!c10::IndexError::IndexError [<unknown file> @ <unknown line number>]\n00007FFB45D55ED100007FFB45D55A10 torch_cpu.dll!at::native::select [<unknown file> @ <unknown line number>]\n00007FFB4602A9FE00007FFB45FAB700 torch_cpu.dll!at::zeros_out [<unknown file> @ <unknown line number>]\n00007FFB45AF844A00007FFB45AED8A0 torch_cpu.dll!torch::nn::functional::BatchNormFuncOptions::~BatchNormFuncOptions [<unknown file> @ <unknown line number>]\n00007FFB45EF843A00007FFB45E73840 torch_cpu.dll!at::native::mkldnn_sigmoid_ [<unknown file> @ <unknown line number>]\n00007FFB45F9751100007FFB45F97450 torch_cpu.dll!at::select [<unknown file> @ <unknown line number>]\n00007FFB4714FDA500007FFB47137970 torch_cpu.dll!torch::autograd::GraphRoot::apply [<unknown file> @ <unknown line number>]\n00007FFB45AF844A00007FFB45AED8A0 torch_cpu.dll!torch::nn::functional::BatchNormFuncOptions::~BatchNormFuncOptions [<unknown file> @ <unknown line number>]\n00007FFB45EF843A00007FFB45E73840 torch_cpu.dll!at::native::mkldnn_sigmoid_ [<unknown file> @ <unknown line number>]\n00007FFB4606026100007FFB460601A0 torch_cpu.dll!at::Tensor::select [<unknown file> @ <unknown line number>]\n00007FFB470DB3F900007FFB470DB050 torch_cpu.dll!torch::autograd::SavedVariable::reset_grad_function [<unknown file> @ <unknown line number>]\n00007FFB470A0EC400007FFB470A0D90 torch_cpu.dll!torch::autograd::generated::MaxBackward1::apply [<unknown file> @ <unknown line number>]\n00007FFB4707D96700007FFB4707D760 torch_cpu.dll!torch::autograd::Node::operator() [<unknown file> @ <unknown line number>]\n00007FFB475559F900007FFB475554A0 torch_cpu.dll!torch::autograd::Engine::add_thread_pool_task [<unknown file> @ <unknown line number>]\n00007FFB475565A500007FFB47556290 torch_cpu.dll!torch::autograd::Engine::evaluate_function [<unknown file> @ <unknown line number>]\n00007FFB4755B52C00007FFB4755B220 torch_cpu.dll!torch::autograd::Engine::thread_main [<unknown file> @ <unknown line number>]\n00007FFB47557BFF00007FFB47557A10 torch_cpu.dll!torch::autograd::Engine::execute_with_graph_task [<unknown file> @ <unknown line number>]\n00007FFB6859307800007FFB6856C550 torch_python.dll!THPShortStorage_New [<unknown file> @ <unknown line number>]\n00007FFB4755793D00007FFB47557600 torch_cpu.dll!torch::autograd::Engine::execute [<unknown file> @ <unknown line number>]\n00007FFB68592F4400007FFB6856C550 torch_python.dll!THPShortStorage_New [<unknown file> @ <unknown line number>]\n00007FFB6859190000007FFB6856C550 torch_python.dll!THPShortStorage_New [<unknown file> @ <unknown line number>]\n00007FFB6CFDE9F500007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFDF2BF00007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFE04E900007FFB6CFDF4F0 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFB6CFC8EB600007FFB6CFC8D10 python37.dll!PyEval_EvalCodeWithName [<unknown file> @ <unknown line number>]\n00007FFB6CFDF38700007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFDFDA200007FFB6CFDF4F0 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFB6CFC8EB600007FFB6CFC8D10 python37.dll!PyEval_EvalCodeWithName [<unknown file> @ <unknown line number>]\n00007FFB6CFDF38700007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFDF8F300007FFB6CFDF4F0 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFB6CFC8EB600007FFB6CFC8D10 python37.dll!PyEval_EvalCodeWithName [<unknown file> @ <unknown line number>]\n00007FFB6CFA732F00007FFB6CFA718C python37.dll!PyErr_Clear [<unknown file> @ <unknown line number>]\n00007FFB6CFA720500007FFB6CFA718C python37.dll!PyErr_Clear [<unknown file> @ <unknown line number>]\n00007FFB6CFDE75000007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFDF2BF00007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFDF99F00007FFB6CFDF4F0 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFB6CFC517400007FFB6CFC4F2C python37.dll!PyObject_GetAttrId [<unknown file> @ <unknown line number>]\n00007FFB6D0258AC00007FFB6CFFE9B0 python37.dll!PyErr_NoMemory [<unknown file> @ <unknown line number>]\n00007FFB6CFC517400007FFB6CFC4F2C python37.dll!PyObject_GetAttrId [<unknown file> @ <unknown line number>]\n00007FFB6D0258AC00007FFB6CFFE9B0 python37.dll!PyErr_NoMemory [<unknown file> @ <unknown line number>]\n00007FFB6CFC517400007FFB6CFC4F2C python37.dll!PyObject_GetAttrId [<unknown file> @ <unknown line number>]\n00007FFB6CFDE77100007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFDF0FC00007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFDF8F300007FFB6CFDF4F0 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFB6CFDF25B00007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFDF99F00007FFB6CFDF4F0 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFB6CFDF25B00007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFDF8F300007FFB6CFDF4F0 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFB6CFC8EB600007FFB6CFC8D10 python37.dll!PyEval_EvalCodeWithName [<unknown file> @ <unknown line number>]\n00007FFB6CFC8B3A00007FFB6CFC8980 python37.dll!PyFunction_FastCallDict [<unknown file> @ <unknown line number>]\n00007FFB6CFC7AEA00007FFB6CFC7740 python37.dll!PyMethodDef_RawFastCallDict [<unknown file> @ <unknown line number>]\n00007FFB6CFEED1400007FFB6CFEEB60 python37.dll!PySlice_New [<unknown file> @ <unknown line number>]\n00007FFB6CFE066400007FFB6CFDF4F0 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFB6CFC8EB600007FFB6CFC8D10 python37.dll!PyEval_EvalCodeWithName [<unknown file> @ <unknown line number>]\n00007FFB6CFDF38700007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFE04E900007FFB6CFDF4F0 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFB6CFC517400007FFB6CFC4F2C python37.dll!PyObject_GetAttrId [<unknown file> @ <unknown line number>]\n00007FFB6D11F35600007FFB6D11BA64 python37.dll!PyAST_Optimize [<unknown file> @ <unknown line number>]\n00007FFB6CFDE75000007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFDF2BF00007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFB6CFDF99F00007FFB6CFDF4F0 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFB6CFC8EB600007FFB6CFC8D10 python37.dll!PyEval_EvalCodeWithName [<unknown file> @ <unknown line number>]\n00007FFB6CFDF38700007FFB6CFDE6A0 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n"
     ]
    }
   ],
   "source": [
    "gamma_reg = 0.01\n",
    "lambda_loss= 0.5\n",
    "\n",
    "simnet = SimNet()\n",
    "simnet.apply(init_weights_disc)\n",
    "\n",
    "optimizerSimNet = torch.optim.SGD([\n",
    "                                    {'params': simnet.disc.parameters(), 'lr': 1e-2},\n",
    "                                    {'params': simnet.hsim.parameters(), 'lr': 1e-2},\n",
    "                                    {'params': simnet.fnet.parameters()},\n",
    "                                    {'params': simnet.gnet.parameters()}],                                 \n",
    "                                lr=1e-3, momentum=0.99, weight_decay=1e-5)\n",
    "\n",
    "loss_class = 0\n",
    "loss_disc = 0\n",
    "\n",
    "for epoch in range(3): # 3 full passes over the data\n",
    "    \n",
    "    num_batches = len(train_USPS_transformed)\n",
    "\n",
    "    for i in range(0, num_batches):\n",
    "        \n",
    "        MNIST_batch = train_MNIST_transformed[i]\n",
    "        USPS_batch = train_USPS_transformed[i]\n",
    "        \n",
    "        X_MNIST, y_MNIST = MNIST_batch\n",
    "        X_USPS, y_USPS = USPS_batch\n",
    "                \n",
    "        simnet.zero_grad()\n",
    "#         optimizerSimNet.zero_grad()\n",
    "                \n",
    "        [source_class_output, source_domain_output, Regularizer] = simnet(X_MNIST, prototype_images)\n",
    "        [target_class_output, target_domain_output, Regularizer] = simnet(X_USPS, prototype_images)\n",
    "        \n",
    "        \n",
    "        loss_class = 0\n",
    "        \n",
    "###### 'Our' implementation of classifier loss as described in the paper ######\n",
    "                \n",
    "       #for j in range(0,len(y_MNIST)):\n",
    "            #h_jj = source_class_output[j][y_MNIST[j]]\n",
    "            #h_jk = torch.exp(source_class_output[j])\n",
    "            #h_k = torch.sum(h_jk)\n",
    "            \n",
    "            #loss_class -= (h_jj - torch.log(h_k + 1e-7))\n",
    "            \n",
    "        #print(Regularizer) # this gets absurdly large?\n",
    "            \n",
    "        #loss_class += Regularizer\n",
    "\n",
    "##### Cross_entropy classifier loss #####\n",
    "            \n",
    "        # For cross_entropy loss to work you have to uncomment F.softmax in forward function of hSim()    \n",
    "        \n",
    "        #loss_class = F.cross_entropy(source_class_output, y_MNIST) + gamma_reg * Regularizer\n",
    "        \n",
    "        \n",
    "        loss_disc = - torch.sum(torch.log(source_domain_output + 1e-7)) - torch.sum(torch.log(1 - target_domain_output+1e-7))\n",
    "\n",
    "        total_loss = loss_class - lambda_loss * loss_disc        \n",
    "        total_loss.backward()\n",
    "        \n",
    "        optimizerSimNet.step()\n",
    "        \n",
    "        print(\"loss_class: \" + str(loss_class))\n",
    "        print(\"loss_disc: \" + str(loss_disc))\n",
    "        \n",
    "#         if i == num_batches-1:\n",
    "#             print(\"loss_class: \" + str(loss_class))\n",
    "#             print(\"loss_disc: \" + str(loss_disc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4973, 0.4893, 0.4992, 0.4977, 0.4964, 0.4988, 0.4975, 0.4888, 0.4929,\n",
      "        0.4962, 0.4424, 0.4975, 0.4990, 0.4876, 0.4986, 0.4905, 0.4983, 0.4982,\n",
      "        0.4856, 0.4981, 0.4984, 0.4988, 0.4983, 0.4843, 0.4934, 0.4892, 0.4986,\n",
      "        0.4783, 0.4857, 0.4974, 0.4976, 0.4989], grad_fn=<SelectBackward>)\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<CopySlices>)\n",
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
      "        4, 0, 7, 4, 0, 1, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "for test_batch in test_MNIST_transformed:\n",
    "    \n",
    "    X, y = test_batch\n",
    "    [class_output, domain_output, Regi] = simnet(X, prototype_images)\n",
    "    \n",
    "    print(domain_output)\n",
    "    print(class_output)\n",
    "    print(y)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
